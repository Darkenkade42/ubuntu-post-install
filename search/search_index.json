{
    "docs": [
        {
            "location": "/", 
            "text": "After-Effects\n\n\nAn effortless post install script for Ubuntu \n\n\nWhy\n\n\nUpgrading a Linux machine comes with lot of headache. Somethings might break, somethings might not work or you might just want to\nstart fresh. Beauty of Linux is almost everything is scriptable. Re-installing is just a matter of putting your favorite distribution on USB, install and configuring it. If you do it often and over a fleet of machines, then its a pain. You can run a few scripts to automate it, but they are not so flexible. A package changed its name? PPA not available for the current release? You need to edit your script, test it and run it.\n\n\nHow\n\n\nWhat if your script could be \"configured\"? Just add the package you want to install to your config file. No need to search through code to do it. Separating your preferences and package lists from the script frees you from writing the script every time a new release comes around. This project helps you do just that. Its poor man's Chef. Most of your preferences and configurations are separate from script.\n\n\nReally? A shell-script\n\n\n\n\nYes! Because it has almost zero dependencies. No need to have Python or Ruby or other dependencies. Someone can edit it to fit their needs too.\n\n\nHow to\n\n\nSee \nGetting Started\n.\n\n\nSupported Distros\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI have not tested the script on following distros. Because they use ubuntu as their base,\nIt should work fine. But no promises.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nPlease check \nSupported-Distros\n for complete list of supported distros.\n\n\n\n\nFeatures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenshots", 
            "title": "Introduction"
        }, 
        {
            "location": "/#after-effects", 
            "text": "An effortless post install script for Ubuntu", 
            "title": "After-Effects"
        }, 
        {
            "location": "/#why", 
            "text": "Upgrading a Linux machine comes with lot of headache. Somethings might break, somethings might not work or you might just want to\nstart fresh. Beauty of Linux is almost everything is scriptable. Re-installing is just a matter of putting your favorite distribution on USB, install and configuring it. If you do it often and over a fleet of machines, then its a pain. You can run a few scripts to automate it, but they are not so flexible. A package changed its name? PPA not available for the current release? You need to edit your script, test it and run it.", 
            "title": "Why"
        }, 
        {
            "location": "/#how", 
            "text": "What if your script could be \"configured\"? Just add the package you want to install to your config file. No need to search through code to do it. Separating your preferences and package lists from the script frees you from writing the script every time a new release comes around. This project helps you do just that. Its poor man's Chef. Most of your preferences and configurations are separate from script.", 
            "title": "How"
        }, 
        {
            "location": "/#really-a-shell-script", 
            "text": "Yes! Because it has almost zero dependencies. No need to have Python or Ruby or other dependencies. Someone can edit it to fit their needs too.", 
            "title": "Really? A shell-script"
        }, 
        {
            "location": "/#how-to", 
            "text": "See  Getting Started .", 
            "title": "How to"
        }, 
        {
            "location": "/#supported-distros", 
            "text": "I have not tested the script on following distros. Because they use ubuntu as their base,\nIt should work fine. But no promises.         Tip  Please check  Supported-Distros  for complete list of supported distros.", 
            "title": "Supported Distros"
        }, 
        {
            "location": "/#features", 
            "text": "", 
            "title": "Features"
        }, 
        {
            "location": "/#screenshots", 
            "text": "", 
            "title": "Screenshots"
        }, 
        {
            "location": "/getting-started/", 
            "text": "How to use?\n\n\nInstall Ubuntu\n\n\nInstall (if you haven't already) your choice of Ubuntu/Derivative as you would( If you wish to automate that too, you can use preseed.cfg file)\n\n\nStep 1: Get the script\n\n\nWithout Git\n\n\nRun this in Terminal\n\n\nwget -Nnv https://raw.githubusercontent.com/tprasadtp/ubuntu-post-install/master/get-after-effects.sh -O - | bash\n\n\n\n\n\nWith Git\n\n\nIf you already have git on your system already you can use,\n\n\ngit clone --depth 1 https://github.com/tprasadtp/ubuntu-post-install.git \n cd ubuntu-post-install\n\n\n\n\n\nStep 2: Update the lists or config.yml to suit your needs (Optional)\n\n\nUpdate the list or config files to suit your needs. Change PPAs, add or delete packages to list, tweak variables etc.\nPlease see \nConfiguration\n \n \nTasks\n for more details.\n\n\nStep 3: Run it\n\n\nRun the script as \nroot\n. You will get an error if you do not run the script as root.\n\n\n\n\nTip\n\n\nBefore you run the script, make sure that its executable.\n\n\n\n\n  sudo ./after-effects -Y -C \nyour config.yml\n\n\n\n\n\nTo use lists\n\n\nsudo ./after-effects -L\n\n\n\n\n\nNote for using this script inside docker containers\n\n\nIf you are running this in a docker container, you probably are root.\n\n\nIts possible that you might be missing \nsudo\n package. So In that case just run it as \n./after-effects\n. Be warned! You probably are missing several dependencies of the script!", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#how-to-use", 
            "text": "", 
            "title": "How to use?"
        }, 
        {
            "location": "/getting-started/#install-ubuntu", 
            "text": "Install (if you haven't already) your choice of Ubuntu/Derivative as you would( If you wish to automate that too, you can use preseed.cfg file)", 
            "title": "Install Ubuntu"
        }, 
        {
            "location": "/getting-started/#step-1-get-the-script", 
            "text": "", 
            "title": "Step 1: Get the script"
        }, 
        {
            "location": "/getting-started/#without-git", 
            "text": "Run this in Terminal  wget -Nnv https://raw.githubusercontent.com/tprasadtp/ubuntu-post-install/master/get-after-effects.sh -O - | bash", 
            "title": "Without Git"
        }, 
        {
            "location": "/getting-started/#with-git", 
            "text": "If you already have git on your system already you can use,  git clone --depth 1 https://github.com/tprasadtp/ubuntu-post-install.git   cd ubuntu-post-install", 
            "title": "With Git"
        }, 
        {
            "location": "/getting-started/#step-2-update-the-lists-or-configyml-to-suit-your-needs-optional", 
            "text": "Update the list or config files to suit your needs. Change PPAs, add or delete packages to list, tweak variables etc.\nPlease see  Configuration     Tasks  for more details.", 
            "title": "Step 2: Update the lists or config.yml to suit your needs (Optional)"
        }, 
        {
            "location": "/getting-started/#step-3-run-it", 
            "text": "Run the script as  root . You will get an error if you do not run the script as root.   Tip  Before you run the script, make sure that its executable.     sudo ./after-effects -Y -C  your config.yml   To use lists  sudo ./after-effects -L   Note for using this script inside docker containers  If you are running this in a docker container, you probably are root.  Its possible that you might be missing  sudo  package. So In that case just run it as  ./after-effects . Be warned! You probably are missing several dependencies of the script!", 
            "title": "Step 3: Run it"
        }, 
        {
            "location": "/faq/dependencies/", 
            "text": "Dependencies\n\n\nWhat do I need to run this\n\n\nUsually nothing extra! Your base Ubuntu install comes with all the commands/utilities this script uses, unless you are running this on Ubuntu docker image.\n\n\nCore dependencies\n\n\nThe script depends on following utilities which are usually present on a typical Ubuntu/Ubuntu based installation. If these packages are not installed, script will exit with error code 1.\n\n\n\n\nInstall Dependencies\n\n\nsudo apt-get install -y --no-install-recommends lsb-release curl whiptail coreutils iputils-ping procps gpgv wget\n\n\n\n\n\n\n\n\n\nlsb-release\n, for determining the release and distribution.\n\n\nwhiptail\n, to display the menu.\n\n\ncoreutils\n cut, tr, grep etc.\n\n\nwget\n, to get deb packages, report stats, get version information.\n\n\niputils-ping\n, to test connectivity.\n\n\nprocps\n to check running processes\n\n\ngpg\n, \ngpgv\n to check signatures \n add repositories\n\n\nawk\n, \nsed\n to parse configs\n\n\nbash (4.x)\n\n\n\n\n\n\nNote on Debian\n\n\nDebian releases, [especially in docker] images sometimes do not have \nps\n binary from \nprocps\n pre installed. Please install the dependency packages before running the script.\n\n\n\n\nAdditional packages installed\n\n\nSome tasks might install packages automatically, which are required to perform certain actions.\n\n\nAdditional APT packages installed\nSome apt packages will be installed automatically, as they are necessary to perform selected tasks.\n\n\nFor repository related tasks\n\n\n\n\napt-transport-https\n\n\nca-certificates\n\n\ncurl\n\n\ngpg\n\n\nsoftware-properties-common\n\n\n\n\nFor installing python packages\n\n\n\n\npython-pip (for python 2)\n\n\npython3-pip (for python 3)\n\n\n\n\nFor resetting repositories\n\n\n\n\nppa-purge\n\n\n\n\nAdditional dependencies of these packages will also be installed.", 
            "title": "Dependecies"
        }, 
        {
            "location": "/faq/dependencies/#dependencies", 
            "text": "", 
            "title": "Dependencies"
        }, 
        {
            "location": "/faq/dependencies/#what-do-i-need-to-run-this", 
            "text": "Usually nothing extra! Your base Ubuntu install comes with all the commands/utilities this script uses, unless you are running this on Ubuntu docker image.", 
            "title": "What do I need to run this"
        }, 
        {
            "location": "/faq/dependencies/#core-dependencies", 
            "text": "The script depends on following utilities which are usually present on a typical Ubuntu/Ubuntu based installation. If these packages are not installed, script will exit with error code 1.   Install Dependencies  sudo apt-get install -y --no-install-recommends lsb-release curl whiptail coreutils iputils-ping procps gpgv wget     lsb-release , for determining the release and distribution.  whiptail , to display the menu.  coreutils  cut, tr, grep etc.  wget , to get deb packages, report stats, get version information.  iputils-ping , to test connectivity.  procps  to check running processes  gpg ,  gpgv  to check signatures   add repositories  awk ,  sed  to parse configs  bash (4.x)    Note on Debian  Debian releases, [especially in docker] images sometimes do not have  ps  binary from  procps  pre installed. Please install the dependency packages before running the script.", 
            "title": "Core dependencies"
        }, 
        {
            "location": "/faq/dependencies/#additional-packages-installed", 
            "text": "Some tasks might install packages automatically, which are required to perform certain actions.  Additional APT packages installed Some apt packages will be installed automatically, as they are necessary to perform selected tasks.", 
            "title": "Additional packages installed"
        }, 
        {
            "location": "/faq/dependencies/#for-repository-related-tasks", 
            "text": "apt-transport-https  ca-certificates  curl  gpg  software-properties-common", 
            "title": "For repository related tasks"
        }, 
        {
            "location": "/faq/dependencies/#for-installing-python-packages", 
            "text": "python-pip (for python 2)  python3-pip (for python 3)", 
            "title": "For installing python packages"
        }, 
        {
            "location": "/faq/dependencies/#for-resetting-repositories", 
            "text": "ppa-purge   Additional dependencies of these packages will also be installed.", 
            "title": "For resetting repositories"
        }, 
        {
            "location": "/faq/distros/", 
            "text": "Supported Distros\n\n\nIn short? Ubuntu, its official flavors (Kubuntu,Ubuntu Mate etc), Linux Mint and Elementary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI have not tested the script on following distros, but since they use ubuntu as their base,\nIt should work fine. But no promises.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout 32 bit \n ARM Support\n\n\nThough 32 bit \n ARM is supported, Testing in Travis CI, containers and locally all are done using 64 bit machine and containers. If something breaks please report it and use it with caution on 32 bit machines.\n\n\nSome repositories are not available for ARM and 32 bit architecture.\n\n\nSince 17.10 Ubuntu no longer provides 32 bit ISO images. You have to use Ubuntu flavors like Lubuntu. Xubuntu or use minimal ISO.\n\n\n\n\n\n\n\n\nWarning!\n\n\nScript will exit, if it cannot recognize the distribution.\n\n\n\n\nA Complete  list of supported distributions is given below.\n\n\n\n\n\n\n\n\nDistribution\n\n\nCode name/Version\n\n\nSupported\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nUbuntu 18.04\n\n\nBionic Beaver\n\n\nYes\n\n\n\n\n\n\n\n\nUbuntu 16.04\n\n\nXenial Xerus\n\n\nYes\n\n\n\n\n\n\n\n\nUbuntu 14.04\n\n\nTrusty Thar\n\n\nYes\n\n\n\n\n\n\n\n\nUbuntu 18.10\n\n\nCosmic Cuttlefish\n\n\n--\n\n\nOnly use it for testing\n\n\n\n\n\n\nUbuntu 17.10\n\n\nArtful Aardvark\n\n\nNo\n\n\nReached EOL on July 20\nth\n 2018\n\n\n\n\n\n\nUbuntu 17.10\n\n\nZesty Zapus\n\n\nNo\n\n\nReached EOL on Jan 13\nth\n 2018\n\n\n\n\n\n\nLinux Mint 17\n\n\nQuina\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 17.1\n\n\nRebecca\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 17.2\n\n\nRafaela\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 17.3\n\n\nRosa\n\n\nYes\n\n\n\n\n\n\n\n\nLinux Mint 18\n\n\nSarah\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 18.1\n\n\nSerena\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 18.2\n\n\nSonya\n\n\nYes\n\n\n\n\n\n\n\n\nLinux-Mint 18.3\n\n\nSylvia\n\n\nYes\n\n\n\n\n\n\n\n\nLinux Mint 19\n\n\nTara\n\n\nYes\n\n\n\n\n\n\n\n\nDebian 8\n\n\nJessie\n\n\nYes\n\n\n\n\n\n\n\n\nDebian 9\n\n\nStretch\n\n\nYes\n\n\n\n\n\n\n\n\nElementary-OS\n\n\nFreya\n\n\nYes\n\n\nNot tested\n\n\n\n\n\n\nElementary-OS 0.4\n\n\nLoki\n\n\nYes\n\n\nNot tested\n\n\n\n\n\n\nElementary-OS 5.0\n\n\nJuno\n\n\nYes\n\n\nNot tested\n\n\n\n\n\n\nBudgie Remix\n\n\n16.04\n\n\nYes\n\n\n\n\n\n\n\n\nPoP! OS\n\n\n17.10 \n 18.04\n\n\nYes\n\n\nNot tested\n\n\n\n\n\n\nLinux-Lite\n\n\n3.X\n\n\nYes\n\n\n(Based on Ubuntu 16.04)\n\n\n\n\n\n\nZorin-OS\n\n\n12.X\n\n\nYes\n\n\n(Based on Ubuntu 16.04)\n\n\n\n\n\n\nBodhi Linux\n\n\n4\n\n\nYes\n\n\n(Based on Ubuntu 16.04)\n\n\n\n\n\n\nKDE Neon\n\n\nBased on Ubuntu LTS\n\n\nMight be buggy\n\n\nNot Tested\n\n\n\n\n\n\nPeppermint 9\n\n\nBased on Ubuntu 18.04\n\n\nYes\n\n\nNot Tested\n\n\n\n\n\n\nPeppermint 8\n\n\nBased on Ubuntu 16.04\n\n\nYes\n\n\nNot tested\n\n\n\n\n\n\n\n\nPre-Release and development builds\n\n\nSupport for Ubuntu Pre-release builds, Elementary OS Juno are \nexperimental\n and things might break.\n\n\nThey have not been released in stable release channels and are considered development versions of the release.\n\n\nIt is strongly advised to use them in a chroot or a in a VM and \nnot\n as a daily driver.\n\n\nDebian Buster is in testing. Please use it with caution.\n\n\n\n\n\n\nNew App-store on Linux Mint 18.3 and above\nLinux mint 18.3 \n later releases uses a new App-Store, from which you can directly install Chrome and other popular tools. There may be some conflicts in the \n/etc/apt/sources.list.d\n. Where, a single repository might be configured multiple times with same priority. Use it with caution. The scripts are not tested on Travis on Linux Mint.", 
            "title": "Distros"
        }, 
        {
            "location": "/faq/distros/#supported-distros", 
            "text": "In short? Ubuntu, its official flavors (Kubuntu,Ubuntu Mate etc), Linux Mint and Elementary.            I have not tested the script on following distros, but since they use ubuntu as their base,\nIt should work fine. But no promises.        About 32 bit   ARM Support  Though 32 bit   ARM is supported, Testing in Travis CI, containers and locally all are done using 64 bit machine and containers. If something breaks please report it and use it with caution on 32 bit machines.  Some repositories are not available for ARM and 32 bit architecture.  Since 17.10 Ubuntu no longer provides 32 bit ISO images. You have to use Ubuntu flavors like Lubuntu. Xubuntu or use minimal ISO.     Warning!  Script will exit, if it cannot recognize the distribution.   A Complete  list of supported distributions is given below.     Distribution  Code name/Version  Supported  Notes      Ubuntu 18.04  Bionic Beaver  Yes     Ubuntu 16.04  Xenial Xerus  Yes     Ubuntu 14.04  Trusty Thar  Yes     Ubuntu 18.10  Cosmic Cuttlefish  --  Only use it for testing    Ubuntu 17.10  Artful Aardvark  No  Reached EOL on July 20 th  2018    Ubuntu 17.10  Zesty Zapus  No  Reached EOL on Jan 13 th  2018    Linux Mint 17  Quina  Yes     Linux-Mint 17.1  Rebecca  Yes     Linux-Mint 17.2  Rafaela  Yes     Linux-Mint 17.3  Rosa  Yes     Linux Mint 18  Sarah  Yes     Linux-Mint 18.1  Serena  Yes     Linux-Mint 18.2  Sonya  Yes     Linux-Mint 18.3  Sylvia  Yes     Linux Mint 19  Tara  Yes     Debian 8  Jessie  Yes     Debian 9  Stretch  Yes     Elementary-OS  Freya  Yes  Not tested    Elementary-OS 0.4  Loki  Yes  Not tested    Elementary-OS 5.0  Juno  Yes  Not tested    Budgie Remix  16.04  Yes     PoP! OS  17.10   18.04  Yes  Not tested    Linux-Lite  3.X  Yes  (Based on Ubuntu 16.04)    Zorin-OS  12.X  Yes  (Based on Ubuntu 16.04)    Bodhi Linux  4  Yes  (Based on Ubuntu 16.04)    KDE Neon  Based on Ubuntu LTS  Might be buggy  Not Tested    Peppermint 9  Based on Ubuntu 18.04  Yes  Not Tested    Peppermint 8  Based on Ubuntu 16.04  Yes  Not tested     Pre-Release and development builds  Support for Ubuntu Pre-release builds, Elementary OS Juno are  experimental  and things might break.  They have not been released in stable release channels and are considered development versions of the release.  It is strongly advised to use them in a chroot or a in a VM and  not  as a daily driver.  Debian Buster is in testing. Please use it with caution.    New App-store on Linux Mint 18.3 and above Linux mint 18.3   later releases uses a new App-Store, from which you can directly install Chrome and other popular tools. There may be some conflicts in the  /etc/apt/sources.list.d . Where, a single repository might be configured multiple times with same priority. Use it with caution. The scripts are not tested on Travis on Linux Mint.", 
            "title": "Supported Distros"
        }, 
        {
            "location": "/faq/errors/", 
            "text": "Errors\n\n\nWhat if I get an error saying Unknown Distribution/Release?\n\n\nThat usually means you are running a Distribution which is not supported or too old or a derivative which is not recognized by the script. However it also might be possible that \nlsb-release\n package is missing from your system. Since the script depends on it for determining what is the code-name of the release it will fail.\nYou might see an error like this,\n\n\n./after-effects: line 41: lsb_release: command not found\n\n\n./after-effects: line 42: lsb_release: command not found\n\n\n./after-effects: line 43: lsb_release: command not found\n\n\n./after-effects: line 44: lsb_release: command not found\n\n\n[    Notice     ] Following details were recognized by the Script.\n\n\n[     Info      ] Distro:\n\n\n[     Info      ] Version:\n\n\n[     Info      ] Code Name:\n\n\n[     Info      ] Architecture: amd64\n\n\n[     Info      ] Path for sources.list.d: /etc/apt/sources.list.d\n\n\n[    WARNING    ] Will automatically assume yes for all the options available in the script!\n\n\n[   Simulating  ] is set to true\n\n\n[  Derivatives  ] Checking for Ubuntu based Distributions\n\n\n[     Error!    ] Unknown Distribution/Release.\n\n\n[    Notice     ] This Script is not designed to run on this () distro/release.\n\n\n\n\n\n\n\nIt means that you do not have \nlsb-release\n package installed. It happens usually on docker containers. See \nWhat are its dependencies? What do I need on my system to run this?\n\n\nInstall \nlsb-release\n package using \napt-get -y install lsb-release\n\n\nIn the case above you are probably missing other dependencies as well. It might be a good idea to install those dependencies first.\n\n\n\n\nWhat if I get an error saying this release of Ubuntu is no longer supported?\n\n\n[      EOL      ] This release of Ubuntu is no longer supported.\n\n\n[    Notice     ] zesty reached EOL on January 13th, 2018.\n\n\n[    Notice     ] Please use a supported version of Ubuntu.\n\n\n[     Info      ] Please visit the link below for information on how to upgrade.\n\n\n\n\n\nSSL Errors\n\n\n[     Error!    ] Something went wrong while retrieving /tmp/api-version.yml.\n\n\n[     Error!    ] Error Getting file.\n\n\n\n\n\nTry running \nwget https://ae.prasadt.com/api/version.yml\n. If you see SSL errors, that means that your CA bundle is out of date.\nThis project uses Amazon Root CA \n LetsEncrypt for SSL, make sure that your system trusts these.\n\n\nScript throws a bunch of errors or got struck or hangs\n\n\n\n\nReport\n\n\nWell, that shouldn't have happened. Please consider opening an issue on \nGithub\n.\n\n\n\n\nHow to recover\n\n\n\n\nIf you know where it was stuck/errored, just re-run the task(s) which were not completed. If you don't know, go and check log file. Each task is labeled and is clearly logged before starting and after completing. Just run the tasks which did not complete. You don't have to re-download the packages you have already downloaded, because they are already cached by apt-get.\n\n\nRemember, some operations of the script can be very lengthy and can involve lots of downloads (If you used default list files, expect up to 2 GB of traffic). So, it might appear that script is stuck because cursor stops blinking. However it is not the case. If you are unsure please check the logs.\n\n\n\n\n\n\nTip\n\n\nIn rare cases where your script exited while installing a DEB file, which has unmet dependencies, you might see broken packages error. In that case, run \nsudo apt-get install -f\n to fix the broken packages and run the script again.\n\n\n\n\nIssues not mentioned above?\n\n\nIf you see any errors or script hangs/errors please do not hesitate to open an issue on \nGithub\n.", 
            "title": "Errors & Issues"
        }, 
        {
            "location": "/faq/errors/#errors", 
            "text": "", 
            "title": "Errors"
        }, 
        {
            "location": "/faq/errors/#what-if-i-get-an-error-saying-unknown-distributionrelease", 
            "text": "That usually means you are running a Distribution which is not supported or too old or a derivative which is not recognized by the script. However it also might be possible that  lsb-release  package is missing from your system. Since the script depends on it for determining what is the code-name of the release it will fail.\nYou might see an error like this,  ./after-effects: line 41: lsb_release: command not found  ./after-effects: line 42: lsb_release: command not found  ./after-effects: line 43: lsb_release: command not found  ./after-effects: line 44: lsb_release: command not found  [    Notice     ] Following details were recognized by the Script.  [     Info      ] Distro:  [     Info      ] Version:  [     Info      ] Code Name:  [     Info      ] Architecture: amd64  [     Info      ] Path for sources.list.d: /etc/apt/sources.list.d  [    WARNING    ] Will automatically assume yes for all the options available in the script!  [   Simulating  ] is set to true  [  Derivatives  ] Checking for Ubuntu based Distributions  [     Error!    ] Unknown Distribution/Release.  [    Notice     ] This Script is not designed to run on this () distro/release.    It means that you do not have  lsb-release  package installed. It happens usually on docker containers. See  What are its dependencies? What do I need on my system to run this?  Install  lsb-release  package using  apt-get -y install lsb-release  In the case above you are probably missing other dependencies as well. It might be a good idea to install those dependencies first.", 
            "title": "What if I get an error saying Unknown Distribution/Release?"
        }, 
        {
            "location": "/faq/errors/#what-if-i-get-an-error-saying-this-release-of-ubuntu-is-no-longer-supported", 
            "text": "[      EOL      ] This release of Ubuntu is no longer supported.  [    Notice     ] zesty reached EOL on January 13th, 2018.  [    Notice     ] Please use a supported version of Ubuntu.  [     Info      ] Please visit the link below for information on how to upgrade.", 
            "title": "What if I get an error saying this release of Ubuntu is no longer supported?"
        }, 
        {
            "location": "/faq/errors/#ssl-errors", 
            "text": "[     Error!    ] Something went wrong while retrieving /tmp/api-version.yml.  [     Error!    ] Error Getting file.   Try running  wget https://ae.prasadt.com/api/version.yml . If you see SSL errors, that means that your CA bundle is out of date.\nThis project uses Amazon Root CA   LetsEncrypt for SSL, make sure that your system trusts these.", 
            "title": "SSL Errors"
        }, 
        {
            "location": "/faq/errors/#script-throws-a-bunch-of-errors-or-got-struck-or-hangs", 
            "text": "Report  Well, that shouldn't have happened. Please consider opening an issue on  Github .", 
            "title": "Script throws a bunch of errors or got struck or hangs"
        }, 
        {
            "location": "/faq/errors/#how-to-recover", 
            "text": "If you know where it was stuck/errored, just re-run the task(s) which were not completed. If you don't know, go and check log file. Each task is labeled and is clearly logged before starting and after completing. Just run the tasks which did not complete. You don't have to re-download the packages you have already downloaded, because they are already cached by apt-get.  Remember, some operations of the script can be very lengthy and can involve lots of downloads (If you used default list files, expect up to 2 GB of traffic). So, it might appear that script is stuck because cursor stops blinking. However it is not the case. If you are unsure please check the logs.    Tip  In rare cases where your script exited while installing a DEB file, which has unmet dependencies, you might see broken packages error. In that case, run  sudo apt-get install -f  to fix the broken packages and run the script again.", 
            "title": "How to recover"
        }, 
        {
            "location": "/faq/errors/#issues-not-mentioned-above", 
            "text": "If you see any errors or script hangs/errors please do not hesitate to open an issue on  Github .", 
            "title": "Issues not mentioned above?"
        }, 
        {
            "location": "/faq/linuxmint/", 
            "text": "Linux Mint 17.X and PPA priorities\n\n\n\n\nNote\n\n\nThis applies only for Linux Mint \n17, 17.1\n and \n17.2\n\n\n\n\n\n\nFor some reason, The Mint team decided to make their repository packages set with a priority of 700 in order to overwrite Ubuntu\u2019s priorities. PPAs typically issue a priority of 500, so due to the priority that Mint set, packages provided by the PPA which are already in the official mint repository (upstream Ubuntu as well) are completely ignored. Workaround is to set the priorities to lower for default repositories say 500 in /etc/apt/preferences.d/ or to increase priorities of PPAs to higher (more than 700).\n\n\nThis was changed in Linux Mint 17.3 and no need to change the priorities unless it provides upstream Linux Mint packages. The release notes for mint 17.3 says\n\n\n\n\n\n\nQuote\n\n\nThe \"upstream\" component of the Linux Mint repositories was kept at priority 700. All other components (\"main\", \"import\", \"backport\", \"romeo\") as well as the \"extra\" repository, had their priority lowered to 500.", 
            "title": "Linux Mint"
        }, 
        {
            "location": "/faq/linuxmint/#linux-mint-17x-and-ppa-priorities", 
            "text": "Note  This applies only for Linux Mint  17, 17.1  and  17.2    For some reason, The Mint team decided to make their repository packages set with a priority of 700 in order to overwrite Ubuntu\u2019s priorities. PPAs typically issue a priority of 500, so due to the priority that Mint set, packages provided by the PPA which are already in the official mint repository (upstream Ubuntu as well) are completely ignored. Workaround is to set the priorities to lower for default repositories say 500 in /etc/apt/preferences.d/ or to increase priorities of PPAs to higher (more than 700).  This was changed in Linux Mint 17.3 and no need to change the priorities unless it provides upstream Linux Mint packages. The release notes for mint 17.3 says    Quote  The \"upstream\" component of the Linux Mint repositories was kept at priority 700. All other components (\"main\", \"import\", \"backport\", \"romeo\") as well as the \"extra\" repository, had their priority lowered to 500.", 
            "title": "Linux Mint 17.X and PPA priorities"
        }, 
        {
            "location": "/faq/others/", 
            "text": "Others\n\n\nSupport for Fedora/ Scientific Linux / Open SUSE / RHEL/ CentOS / put your favorite distro\n\n\nIts in the pipeline, but I cannot guarantee anything. Since I do not use anything other than Open SUSE very often, so it might take a while. But you can modify this script very easily to achieve that. You need to do the following things,\n\n\n\n\nReplace apt-get commands with their equivalents (\ndnf\n or \nzypper\n or \nyum\n etc).\n\n\nReplace/Modify package names.\n\n\nChange add-repositories function to point to .repo files.\n\n\nChange \ndpkg\n to \nrpm\n equivalents.\n\n\nSince v5.0 Debian is supported.\n\n\n\n\nTo-Do\n\n\n\n\n Gsettings\n\n\n Replace stupid bash parser with parser written in Go.\n\n\n Nod Modules \n Ruby Gem installations.\n\n\n Option to upload log file to pastebin.\n\n\n Send a notification (Slack? Hipchat? Hangouts Chat?) after tasks are complete. Helpful if you are using ssh.\n\n\n\n\nAdditional notes for sigma users\n\n\n\n\nNote This applies ONLY if you are using the script from sigma server. This does \nNOT APPLY\n for any GitHub branches/tags/releases.\n\n\n\n\n\n\nDO NOT\n use Github version of \nget-after-effects.sh\n to get the script. Please follow the instructions in SETUP.MD [ Only preset on sigma server]. Several packages \n some settings need to be manually configured to point to internal repositories \n mirrors. Bootstrap function will automatically setup things for you.\n\n\nGroups \n NFS mounts are also handled by bootstrap function.\n\n\nCurrently Github branches do not report stats and \nreport_stats\n is just a placeholder.\n\n\nIf you are using the script from sigma server, stats are reported by default unless you disable them. UUID is \nNOT\n random for each run and is based on MAC address of one of your Ethernet devices.(If you have many) \n hostname.\n\n\nScripts have same version number and are always in sync with Github. You can identify the difference by looking at REL_NAME. Release name has \n-sigma\n appended to it. To see release number \n name use \n./after-effects -v\n. You do not have to run this as \nroot\n.\n\n\n\n\nSecurity\n\n\nWell, this isn't very secure or meant to be.\n\n\n\n\nVerify the checksums on Github/Releases or Sigma Server.\n\n\nYou can verify them manually or via \n./after-effects --verify\n. Public Keys should be already in your keyring.", 
            "title": "Others"
        }, 
        {
            "location": "/faq/others/#others", 
            "text": "", 
            "title": "Others"
        }, 
        {
            "location": "/faq/others/#support-for-fedora-scientific-linux-open-suse-rhel-centos-put-your-favorite-distro", 
            "text": "Its in the pipeline, but I cannot guarantee anything. Since I do not use anything other than Open SUSE very often, so it might take a while. But you can modify this script very easily to achieve that. You need to do the following things,   Replace apt-get commands with their equivalents ( dnf  or  zypper  or  yum  etc).  Replace/Modify package names.  Change add-repositories function to point to .repo files.  Change  dpkg  to  rpm  equivalents.  Since v5.0 Debian is supported.", 
            "title": "Support for Fedora/ Scientific Linux / Open SUSE / RHEL/ CentOS / put your favorite distro"
        }, 
        {
            "location": "/faq/others/#to-do", 
            "text": "Gsettings   Replace stupid bash parser with parser written in Go.   Nod Modules   Ruby Gem installations.   Option to upload log file to pastebin.   Send a notification (Slack? Hipchat? Hangouts Chat?) after tasks are complete. Helpful if you are using ssh.", 
            "title": "To-Do"
        }, 
        {
            "location": "/faq/others/#additional-notes-for-sigma-users", 
            "text": "Note This applies ONLY if you are using the script from sigma server. This does  NOT APPLY  for any GitHub branches/tags/releases.    DO NOT  use Github version of  get-after-effects.sh  to get the script. Please follow the instructions in SETUP.MD [ Only preset on sigma server]. Several packages   some settings need to be manually configured to point to internal repositories   mirrors. Bootstrap function will automatically setup things for you.  Groups   NFS mounts are also handled by bootstrap function.  Currently Github branches do not report stats and  report_stats  is just a placeholder.  If you are using the script from sigma server, stats are reported by default unless you disable them. UUID is  NOT  random for each run and is based on MAC address of one of your Ethernet devices.(If you have many)   hostname.  Scripts have same version number and are always in sync with Github. You can identify the difference by looking at REL_NAME. Release name has  -sigma  appended to it. To see release number   name use  ./after-effects -v . You do not have to run this as  root .", 
            "title": "Additional notes for sigma users"
        }, 
        {
            "location": "/faq/others/#security", 
            "text": "Well, this isn't very secure or meant to be.   Verify the checksums on Github/Releases or Sigma Server.  You can verify them manually or via  ./after-effects --verify . Public Keys should be already in your keyring.", 
            "title": "Security"
        }, 
        {
            "location": "/clioptions/", 
            "text": "Command line options\n\n\nConfiguration type\n\n\nYou have two options of configuring this script.\n\n\n\n\nUsing .list files in \ndata\n\n\n\n\n  ./after-effects --lists\n\n\n\n\n\n\n\nUsing YAML files [they can be local or remote]\n\n\n\n\n  ./after-effects --yaml\n\n\n\n\n\nYou need to specify which type to use. Not specifying will throw an error. You cannot mix configurations in YAML and lists.\n\n\n\n\nShorthand flags\n\n\nYou can also use short hand version of the flags \n-Y\n for YAML and \n-L\n for lists. Please note that lowercase case options have different meaning than uppercase ones.\n\n\n\n\nSimulating package installation\n\n\n\n\nUsage\n\n\n./after-effects -s\n\n\n\n\n\nOR\n\n\n./after-effects --simulate\n\n\n\n\n\n\n\nThis flag/option applies to following tasks\n\n\nInstalling apt packages.\n\n\nInstalling Debian package archives (DEBs).\n\n\nInstalling Python packages.\n\n\nUpgrading system packages.\n\n\nPurging unwanted packages.\n\n\n\n\n\n\nFollowing details should explain the behavior of this flag. Please do have a look at exceptions, as all tasks cannot be simulated.\n\n\n\n\nThis option will simulate installing packages mentioned in the lists, using the apt-get in-built dry-run option \napt-get install -s\n to simulate the installation of packages. Nothing will be downloaded except repository metadata (deb files if option is chosen). Packages will not be installed.\n\n\nThis option can be used to check if the files in the lists are compatible/available in the repository.\n\n\nInstallation of DEB files also behaves similarly. It uses \ndpkg -i --dry-run\n to simulate installation.\n\n\nIts a very good idea to simulate installation when you have reconfigured the apps and packages in the list to check what might be error prone.\n\n\nIn case of DEB package files, they \nwill\n be downloaded unlike apt-get package installs.\n\n\n\n\nExceptions - Not everything can be simulated\n\n\nSimulate flag will not simulate adding Repositories or PPAs.\n\n\nIf you want to revert the changes please use \nReset Repositories\n option.\n\n\nPPAs and repositories \nwill\n be added regardless of the flag.\n\n\nPython package installation cannot be simulated. (pip lacks support for it) The script will skip installing apt dependencies and python packages, if simulate option is used.\n  it simulate option is used.\n\n\nAPT package upgrades and apt repository metadata updates cannot be simulated. Only a list of packages upgrade-able will be listed in the log file in case of upgrades.\n\n\nSimulate flag will not simulate installing dependencies for adding or deleting repositories and PPAs.\n\n\n\n\n\n\nSkip Version Checks\n\n\n\n\nUsage\n\n\n./after-effects --no-version-check\n\n\n\n\n\n\n\nScript will warn you and exit if you are not running latest version of the script. You can skip that by using the above option.\n\n\nFix for latest Ubuntu releases\n\n\n\n\nUsage\n\n\n./after-effects -f\n\n\n\n\n\nOR\n\n\n./after-effects --fix\n\n\n\n\n\n\n\nThis flag/option applies to following repositories\n\n\nGoogle Cloud SDK\n\n\nGCSFUSE\n\n\nInSync\n\n\nDocker Community Edition\n\n\nWine HQ\n\n\n\n\n\n\nUsually it takes a while for additional Repositories (Docker, Google Cloud SDK etc) to add support for latest release of Ubuntu. However we can use the previous release for which packages are available. So, using packages built for previous release works fine most of the time. This is also good fix if you are running a alpha or beta release of Ubuntu. These options only work on Ubuntu or distros using ubuntu codenames and Linux Mint. They \nDO NOT\n work on Debian.\n\n\n\n\nBy default this option is disabled.\n\n\nUse \nsudo ./after-effects -f\n or \nsudo ./after-effects --fix\n to enable this.\n\n\nRepositories like Spotify and Google Chrome do not use code names in their repository URLs. So the above workaround is not necessary.\n\n\nDerivatives of Ubuntu will use the code name of Ubuntu on which they are based. For example Linux mint 18.2 Serena will use code name xenial since it is based on Ubuntu 16.04 Xenial Xerus\n\n\nThis option applies only for the latest release mentioned in the variable \ncode_name_latest_release\n. and will be ignored if the release is not latest.\n\n\nVariables in current version are (As of Dec 2017) change them if necessary.\n\n\n\n\nreadonly\n \ncode_name_latest_release\n=\nbionic\n\n\nreadonly\n \ncodename_previous_release\n=\nartful\n\n\nreadonly\n \ncodename_upcoming_release\n=\ncosmic\n\n\n\n\n\nNote for Pre-Release/ development version of Ubuntu\n\n\nIf you are using a pre-release version of Ubuntu, you can use \n--pre-release\n flag to apply the above mentioned fix to pre-release version of Ubuntu.\n\n\nThis flag can be used independent of \n--fix\n. If both are used together then both flags will be applied if the release is upcoming-release.\n\n\nIf the release is stable, only \n--fix\n flag will be valid and \n--pre-release\n is ignored.\n\n\nThis is how it works:  If the repositories are  not available for latest stable release as well, go back a release. Ex. If the pre-release is 18.04 and the repositories is not available for 17.10 as well, we use 17.04 repositories. Usually happens in first few days of development cycle of 18.04.\n\n\n\n\n\n\nSkip confirmation prompts\n\n\n\n\nUsage\n\n\n./after-effects -y\n\n\n\n\n\nOR\n\n\n./after-effects --yes\n\n\n\n\n\n\n\nFrom v3.0 onward, you will be asked for confirmation before performing the task selected. If you would like to bypass this on a CI environments like TRAVIS or for any other reason, you can do so by running the script with \nsudo ./after-effects -y\n or \nsudo ./after-effects --yes\n\n\nPurge not required packages\n\n\n\n\nUsage\n\n\n./after-effects -d\n\n\n\n\n\nOR\n\n\n./after-effects --deboalt\n\n\n\n\n\n\n\nUsually Ubuntu comes with some pre-installed games, packages which you sometimes do not need. This option is a switch to used in purging these packages mentioned in the subsequent sections. Since it is possible that user might purge necessary packages like sudo or other core system components, these just acts like a barrier from accidentally doing so.\n\n\n\n\nWarning\n\n\n\n\nThis flag \nMUST\n be passed, if you intend to purge packages from system. Otherwise you will receive an error.\n\n\nIf you are using YML config file you \nMUST\n set   \npurge_enabled\n:\n \ntrue\n under config.flags. See Example YAML file for more info.\n\n\n\n\n\n\nDelete log file\n\n\n\n\nUsage\n\n\n./after-effects -l\n\n\n\n\n\nOR\n\n\n./after-effects --delete-log\n\n\n\n\n\n\n\nJust a quick way to delete logs generated by this script.\n\n\n\n\nFlag priority\n\n\nIf you pass \n-l\n in the beginning rest of the commands will be ignored, as the script exits after deleting the log!\n\n\n\n\nKeep downloaded DEB files\n\n\n\n\nUsage\n\n\n./after-effects -k\n\n\n\n\n\nOR\n\n\n./after-effects --keep-debs\n\n\n\n\n\n\n\nKeeps packages cached by APT and downloaded DEB packages.\nDefault behavior is to clean apt cache and delete downloaded DEB packages.\n\n\n\n\nPython packages\n\n\nPython package installation does not honor this flag.\n\n\n\n\nHide Remote/local YAML configuration data\n\n\n\n\nUsage\n\n\n./after-effects --hide-config\n\n\n\n\n\n\nHides displaying YAML configuration data in the output.\n\n\nPrefer Local lists\n\n\n\n\nUsage\n\n\n./after-effects -L\n\n\n\n\n\nOR\n\n\n./after-effects --lists\n\n\n\n\n\n\n\nUsing this option, you can chose to use the lists file which you have locally and not worry about YAML and shit.\n\n\nUse Custom Configuration file\n\n\n\n\nUsage\n\n\n./after-effects --config-file \nfilename\n\n\n\n\n\nOR\n\n\n./after-effects -C \nfilename\n\n\n\n\n\n\n\nYou can prefer using custom configuration file you have stored locally [It should be available via local paths or network share. not via ftp or http]. Enabling this option will disable fetching remote configuration even if you have specified \n--remote-yaml\n\n\nUse Custom Version information file\n\n\nScript always checks if its running the latest version available. If not it throws an error and exits. If you wish to skip that, please use \n--no-version-check\n. This is always recommended over using a custom version information file. However it is possible to provide a custom version info file, a YAML file which holds version information.\n\n\n\n\nUsage\n\n\n./after-effects --version-file \nfilename\n\n\n\n\n\nOR\n\n\n./after-effects -V \nfilename\n\n\n\n\n\n\n\nExample version file is in \nconfig\n directory. All the fields are mandatory.\n\n\nRemote YAML configuration file\n\n\n\n\nUsage\n\n\n./after-effects --remote-yaml \nURL to YAML file\n\n\n\n\n\nOR\n\n\n./after-effects -R \nURL to YAML file\n\n\n\n\n\n\n\nYou can specify YAML file to use. Script will fetch it and parse it. Please note that local Config file specified takes priority over \n-R\n. If both -C \n -R are used, only local config file is considered. The file should be available without any soft of interactive logins.\n\n\nDo not report statistics\n\n\n\n\nUsage\n\n\n./after-effects --no-stats\n\n\n\n\n\nOR\n\n\n./after-effects -S\n\n\n\n\n\n\n\nDisables reporting statistics back to server.\n\n\nFollowing things are reported. (Nothing more than that)\n\n\n\n\nA UUID generated for each execution, (its random and is not persistent across runs),\n\n\nHost-name,\n\n\nLast exit code,\n\n\nAmount of RAM \n CPU Model\n\n\nNumber of GPU \n GPU Vendor\n\n\nSystem Architecture (x64/x86/ARM/ARM64),\n\n\nTotal execution time,\n\n\nDistribution name (Ubuntu, Linux Mint etc.),\n\n\nDistribution code name (bionic, artful etc),\n\n\nFeature/Task(s) selected,\n\n\nFlags used,\n\n\nTimezone and system language.\n\n\n\n\nPrivacy Concerns?\n\n\nIf you are freaking out, its a shell script !! You can literally look into it and check what's collected. Why if you ask? I mostly use it on a bunch of machines/VMs and would like to keep an eye on how it did.\n\n\nData will be stored in AWS DynamoDB and Google Firebase Real-time Database.\nData will not be shared with any third party. Period. Only me or my team members will have access\nto it. If you run a search query on google, it probably collects more data than me. API endpoints/PaaS/IaaS provider may log your IP addresses, but script does not and WILL not collect IP addresses.\n\n\nIf you flood the reporting endpoints, you might get HTTP 429 errors as reporting endpoints have rate limits.\n\n\n\n\n\n\nVersion\n\n\n\n\nUsage\n\n\n./after-effect -v\n\n\n\n\n\nOR\n\n\n./after-effects --version\n\n\n\n\n\n\n\nThis will display version info. You do \nnot\n have to be root to run this. For all the other tasks you need to be root or use sudo.", 
            "title": "Options"
        }, 
        {
            "location": "/clioptions/#command-line-options", 
            "text": "", 
            "title": "Command line options"
        }, 
        {
            "location": "/clioptions/#configuration-type", 
            "text": "You have two options of configuring this script.   Using .list files in  data     ./after-effects --lists    Using YAML files [they can be local or remote]     ./after-effects --yaml   You need to specify which type to use. Not specifying will throw an error. You cannot mix configurations in YAML and lists.   Shorthand flags  You can also use short hand version of the flags  -Y  for YAML and  -L  for lists. Please note that lowercase case options have different meaning than uppercase ones.", 
            "title": "Configuration type"
        }, 
        {
            "location": "/clioptions/#simulating-package-installation", 
            "text": "Usage  ./after-effects -s   OR  ./after-effects --simulate    This flag/option applies to following tasks  Installing apt packages.  Installing Debian package archives (DEBs).  Installing Python packages.  Upgrading system packages.  Purging unwanted packages.    Following details should explain the behavior of this flag. Please do have a look at exceptions, as all tasks cannot be simulated.   This option will simulate installing packages mentioned in the lists, using the apt-get in-built dry-run option  apt-get install -s  to simulate the installation of packages. Nothing will be downloaded except repository metadata (deb files if option is chosen). Packages will not be installed.  This option can be used to check if the files in the lists are compatible/available in the repository.  Installation of DEB files also behaves similarly. It uses  dpkg -i --dry-run  to simulate installation.  Its a very good idea to simulate installation when you have reconfigured the apps and packages in the list to check what might be error prone.  In case of DEB package files, they  will  be downloaded unlike apt-get package installs.   Exceptions - Not everything can be simulated  Simulate flag will not simulate adding Repositories or PPAs.  If you want to revert the changes please use  Reset Repositories  option.  PPAs and repositories  will  be added regardless of the flag.  Python package installation cannot be simulated. (pip lacks support for it) The script will skip installing apt dependencies and python packages, if simulate option is used.\n  it simulate option is used.  APT package upgrades and apt repository metadata updates cannot be simulated. Only a list of packages upgrade-able will be listed in the log file in case of upgrades.  Simulate flag will not simulate installing dependencies for adding or deleting repositories and PPAs.", 
            "title": "Simulating package installation"
        }, 
        {
            "location": "/clioptions/#skip-version-checks", 
            "text": "Usage  ./after-effects --no-version-check    Script will warn you and exit if you are not running latest version of the script. You can skip that by using the above option.", 
            "title": "Skip Version Checks"
        }, 
        {
            "location": "/clioptions/#fix-for-latest-ubuntu-releases", 
            "text": "Usage  ./after-effects -f   OR  ./after-effects --fix    This flag/option applies to following repositories  Google Cloud SDK  GCSFUSE  InSync  Docker Community Edition  Wine HQ    Usually it takes a while for additional Repositories (Docker, Google Cloud SDK etc) to add support for latest release of Ubuntu. However we can use the previous release for which packages are available. So, using packages built for previous release works fine most of the time. This is also good fix if you are running a alpha or beta release of Ubuntu. These options only work on Ubuntu or distros using ubuntu codenames and Linux Mint. They  DO NOT  work on Debian.   By default this option is disabled.  Use  sudo ./after-effects -f  or  sudo ./after-effects --fix  to enable this.  Repositories like Spotify and Google Chrome do not use code names in their repository URLs. So the above workaround is not necessary.  Derivatives of Ubuntu will use the code name of Ubuntu on which they are based. For example Linux mint 18.2 Serena will use code name xenial since it is based on Ubuntu 16.04 Xenial Xerus  This option applies only for the latest release mentioned in the variable  code_name_latest_release . and will be ignored if the release is not latest.  Variables in current version are (As of Dec 2017) change them if necessary.   readonly   code_name_latest_release = bionic  readonly   codename_previous_release = artful  readonly   codename_upcoming_release = cosmic   Note for Pre-Release/ development version of Ubuntu  If you are using a pre-release version of Ubuntu, you can use  --pre-release  flag to apply the above mentioned fix to pre-release version of Ubuntu.  This flag can be used independent of  --fix . If both are used together then both flags will be applied if the release is upcoming-release.  If the release is stable, only  --fix  flag will be valid and  --pre-release  is ignored.  This is how it works:  If the repositories are  not available for latest stable release as well, go back a release. Ex. If the pre-release is 18.04 and the repositories is not available for 17.10 as well, we use 17.04 repositories. Usually happens in first few days of development cycle of 18.04.", 
            "title": "Fix for latest Ubuntu releases"
        }, 
        {
            "location": "/clioptions/#skip-confirmation-prompts", 
            "text": "Usage  ./after-effects -y   OR  ./after-effects --yes    From v3.0 onward, you will be asked for confirmation before performing the task selected. If you would like to bypass this on a CI environments like TRAVIS or for any other reason, you can do so by running the script with  sudo ./after-effects -y  or  sudo ./after-effects --yes", 
            "title": "Skip confirmation prompts"
        }, 
        {
            "location": "/clioptions/#purge-not-required-packages", 
            "text": "Usage  ./after-effects -d   OR  ./after-effects --deboalt    Usually Ubuntu comes with some pre-installed games, packages which you sometimes do not need. This option is a switch to used in purging these packages mentioned in the subsequent sections. Since it is possible that user might purge necessary packages like sudo or other core system components, these just acts like a barrier from accidentally doing so.   Warning   This flag  MUST  be passed, if you intend to purge packages from system. Otherwise you will receive an error.  If you are using YML config file you  MUST  set    purge_enabled :   true  under config.flags. See Example YAML file for more info.", 
            "title": "Purge not required packages"
        }, 
        {
            "location": "/clioptions/#delete-log-file", 
            "text": "Usage  ./after-effects -l   OR  ./after-effects --delete-log    Just a quick way to delete logs generated by this script.   Flag priority  If you pass  -l  in the beginning rest of the commands will be ignored, as the script exits after deleting the log!", 
            "title": "Delete log file"
        }, 
        {
            "location": "/clioptions/#keep-downloaded-deb-files", 
            "text": "Usage  ./after-effects -k   OR  ./after-effects --keep-debs    Keeps packages cached by APT and downloaded DEB packages.\nDefault behavior is to clean apt cache and delete downloaded DEB packages.   Python packages  Python package installation does not honor this flag.", 
            "title": "Keep downloaded DEB files"
        }, 
        {
            "location": "/clioptions/#hide-remotelocal-yaml-configuration-data", 
            "text": "Usage  ./after-effects --hide-config   Hides displaying YAML configuration data in the output.", 
            "title": "Hide Remote/local YAML configuration data"
        }, 
        {
            "location": "/clioptions/#prefer-local-lists", 
            "text": "Usage  ./after-effects -L   OR  ./after-effects --lists    Using this option, you can chose to use the lists file which you have locally and not worry about YAML and shit.", 
            "title": "Prefer Local lists"
        }, 
        {
            "location": "/clioptions/#use-custom-configuration-file", 
            "text": "Usage  ./after-effects --config-file  filename   OR  ./after-effects -C  filename    You can prefer using custom configuration file you have stored locally [It should be available via local paths or network share. not via ftp or http]. Enabling this option will disable fetching remote configuration even if you have specified  --remote-yaml", 
            "title": "Use Custom Configuration file"
        }, 
        {
            "location": "/clioptions/#use-custom-version-information-file", 
            "text": "Script always checks if its running the latest version available. If not it throws an error and exits. If you wish to skip that, please use  --no-version-check . This is always recommended over using a custom version information file. However it is possible to provide a custom version info file, a YAML file which holds version information.   Usage  ./after-effects --version-file  filename   OR  ./after-effects -V  filename    Example version file is in  config  directory. All the fields are mandatory.", 
            "title": "Use Custom Version information file"
        }, 
        {
            "location": "/clioptions/#remote-yaml-configuration-file", 
            "text": "Usage  ./after-effects --remote-yaml  URL to YAML file   OR  ./after-effects -R  URL to YAML file    You can specify YAML file to use. Script will fetch it and parse it. Please note that local Config file specified takes priority over  -R . If both -C   -R are used, only local config file is considered. The file should be available without any soft of interactive logins.", 
            "title": "Remote YAML configuration file"
        }, 
        {
            "location": "/clioptions/#do-not-report-statistics", 
            "text": "Usage  ./after-effects --no-stats   OR  ./after-effects -S    Disables reporting statistics back to server.  Following things are reported. (Nothing more than that)   A UUID generated for each execution, (its random and is not persistent across runs),  Host-name,  Last exit code,  Amount of RAM   CPU Model  Number of GPU   GPU Vendor  System Architecture (x64/x86/ARM/ARM64),  Total execution time,  Distribution name (Ubuntu, Linux Mint etc.),  Distribution code name (bionic, artful etc),  Feature/Task(s) selected,  Flags used,  Timezone and system language.   Privacy Concerns?  If you are freaking out, its a shell script !! You can literally look into it and check what's collected. Why if you ask? I mostly use it on a bunch of machines/VMs and would like to keep an eye on how it did.  Data will be stored in AWS DynamoDB and Google Firebase Real-time Database.\nData will not be shared with any third party. Period. Only me or my team members will have access\nto it. If you run a search query on google, it probably collects more data than me. API endpoints/PaaS/IaaS provider may log your IP addresses, but script does not and WILL not collect IP addresses.  If you flood the reporting endpoints, you might get HTTP 429 errors as reporting endpoints have rate limits.", 
            "title": "Do not report statistics"
        }, 
        {
            "location": "/clioptions/#version", 
            "text": "Usage  ./after-effect -v   OR  ./after-effects --version    This will display version info. You do  not  have to be root to run this. For all the other tasks you need to be root or use sudo.", 
            "title": "Version"
        }, 
        {
            "location": "/tasks/", 
            "text": "What can it do?\n\n\nAdd Repositories\n\n\nThis can add the following repositories.\n\n\n\n\nGoogle Earth\n\n\nGoogle Chrome\n\n\nSpotify\n\n\nVisual Studio Code\n\n\nSignal Desktop\n\n\nMendeley Desktop\n\n\nGoogle cloud SDK (google-cloud-sdk \n gcsfuse)\n\n\nKubernetes\n\n\nInsync\n\n\n\n\nUsing \n--fix\n falg\nPlease note that the above repositories are sometimes not updated for latest Ubuntu release and most certainly will not be available for upcoming release of Ubuntu(Alpha/Beta). It might take some time till the repositories are available for the latest release. Use -f or --fix command line option or --pre-release in case you are using a Development version of ubuntu to revert using latest available version of repositories (usually previous Ubuntu release or in case of Beta/Alpha latest stable release of ubuntu). \nFor more info see command line options.\n\n\n\n\nControlling which repository is added using config file\nYou can set your YML file to decide which repository is added. Some repositories may no be supported on your architecture or distribution. Take a look at \nconfig.yml\n for example. If you omit a value, it defaults to false \nALWAYS\n. Do note that if you are using lists default values are different, they are mentioned in below.\n\n\n\n\nDefault Variables if using Lists\n#============================ Switches/ bools ================================\n\n\n  \n# Latest wine builds\n\n  \nadd_winehq_repo\n=\ntrue\n\n\n  \n#Docker community edition\n\n  \nadd_docker_repo\n=\ntrue\n\n\n  \n#Mendeley Desktop\n\n  \nadd_mendeley_repo\n=\nfalse\n\n\n  \n#Spotify\n\n  \nadd_spotify_repo\n=\ntrue\n\n\n  \n#InSync\n\n  \nadd_insync_repo\n=\ntrue\n\n\n  \n#Google Cloud SDK\n\n  \nadd_googlecloud_repo\n=\ntrue\n\n\n  \n#Signal\n\n  \nadd_signal_repo\n=\nfalse\n\n\n  \n#Skype\n\n  \nadd_skype_repo\n=\ntrue\n\n\n  \n#VS code\n\n  \nadd_vscode_repo\n=\ntrue\n\n\n  \n#Google\n\n  \nadd_google_repo\n=\ntrue\n\n\n  \n#Kubernetes\n\n  \nadd_kubernetes_repo\n=\nfalse\n\n\n  \n# Define Data Directory\n\n  \ndata_dir\n=\ndata\n\n\n\n\n\n\n\nCanonical partner repositories\n\n\nCanonical partner repositories are not configured or enabled for derivatives of Ubuntu because thee might be some conflicts.\n\n\n\n\nNote on 32 bit \n ARM Architecture\n\n\n\n\nPlease note that Google Chrome doesn't support 32 bit architecture, please use Chromium.\n\n\nSignal, Skype, Mendeley and Visual studio code do not support 32 bit architecture.\n\n\nSome repositories are not available for ARM architecture.\n\n\n\n\n\n\nAdd personal package archives (PPA)\n\n\n\n\nPPAs can be added using the configuration file in data directory \n./data/ppa.list\n or in the YML file.\n\n\nOnly one ppa entry per line (No comments or anything else anywhere in the file) in the format ppa:{author}/{ppa} for example \nppa\n:\nmozillateam\n/\nfirefox\n-\nnext\n The file will be read and the PPAs will be added from the list.\n\n\nLogs will  show entry in the format \n[date and time] [  PPA-Logs  ] \nlog\n\n\n\n\n\n\nWarning\n\n\n\n\nPPAs should be checked before they are added to the list. Sometimes PPAs listed in the file may not be available for all releases.\n\n\nDebian does not support PPAs.\n\n\n\n\n\n\nInstall apt packages\n\n\n\n\nPackages can be installed by using configuration lists in the data directory. This works similar to ppas\n\n\n\n\n```console\n\n\n\n\n                              APT Lists\n\n\n\n\n\n\n\nThere are seven lists under key config.install.apt.[mentioned from 1-7]\n  1. administration : Contains Administrative packages\n  2. security       : contains Security related tools and packages\n  3. productivity   : Office tools, writing tools, LateX, document tools and other\n                      productivity tools, Email clients, browsers, IM clients etc.\n                    : Example : LateX, TeXStudio, Libre office, pandoc empathy, Thunderbird\n  4. multimedia     : Multimedia tools like media players, audio converters and playes etc.\n  5. development    : IDEs [Spyder, Jetbeans etc], languages [go, python, ruby, rust, java etc],\n                    : Containers [docker lxc rkt etc], Python libraries, compilers [gcc, clang]\n                    : SDKs [AWS SDK, Google Cloud SDK, open-jdk, Tensor Flow], headers and libraries[ocl-icd-dev],\n                    : Anything related to development and *-dev or *-devl packages.\n  6. other          : Everything which does not fit in the above categories.\n                    : Themes, Tools, Utilities like htop etc.\n  7. external       : Any packages which are provided by ppas, or repositories not present in\n                    : base [K/L/Ed/X]-Ubuntu distribution. There's a possibility that the repository might not\n                    : be added or may be unavailable or offline. So Keeping the list separate from\n                    : others packages minimizes errors if there are any.\n  This classification is only for ease of use and need not be strictly followed. You can put\n  'vlc' package in 'security', it will still install fine. This classification helps\n  while writing configs and editing them. Its advised to follow it if your configs\n  tend to get to couple of hundreds of lines. Also YAML file should be a valid YAML.\n\n\n\n\n                 Special list - Purge list\n\n\n\n\n\n\n\nThere is a special package list under key, config.purge or purge.list, which contains list of apt packages to be\n  purged from the system.\n  ```\n\n\n\n\nMake sure that all the packages in the lists are available for your release. Using \n-s\n command line option helps. Also check for the logs for any errors or conflicts.\n\n\n\n\nInstall Debian package archives (.deb files)\n\n\nThis will install deb files specified in the list \ndeb.list\n or YAML config under \nconfig.install.debian_packages\n.\n\n\n\n\nLogs will  show entry in the format \n[\ndate and time\n] [  PKG  ] \nlog\n for dpkg actions and\n\n\nAPT Logs will  show entry in the format \n[\ndate and time\n] [  APT  ] \nlog\n for actions performed by apt commands. (\napt-get install -f\n for missing packages)\n\n\nSimulate\n option will use \n--dry-run\n option in dpkg to Simulate DEB installation.\n\n\nConfiguration file is a \ncsv\n file without headers. first column corresponds to URL ans the second field the file name under which the file is saved.\n\n\nEach DEB file to be installed should have following entry.\n\n\nURL to the deb file which can be accessed using wget\n,\nName of the deb file without any spaces or special chars except hyphen.\n\n\nFor example to install Atom Editor the entry should look like below.\n\n\n\n\nhttps://atom-installer.github.com/v1.21.1/atom-amd64.deb,ATOM-Editor.deb\n\n\n\n\n\n\nFirst part is the URL to the deb file separated by ',' name of the file.\n\n\n\n\n\n\nNote on file names in configuration\n\n\nPlease note that deb file will be  saved with the name mentioned in the file. (DEB file is named \nexactly\n as mentioned in the second field. So if you want them to be named with extension .deb include that in the second field and avoid illegal chars)\n\n\n\n\nInstall Static binaries to /usr/local/bin\n\n\nThis will install binaries \nbin.list\n or YAML config under \nconfig.install.binaries\n.\n\n\n\n\nAPT Logs will  show entry in the format \n[\ndate and time\n] [  APT  ] \nlog\n for actions performed by apt commands. (\napt-get install -f\n for missing packages)\n\n\nSimulate\n option will only download the package but not install it.\n\n\nConfiguration file is a \ncsv\n file without headers. first column corresponds to URL ans the second field the file name under which the file is saved.\n\n\nEach DEB file to be installed should have following entry.\n\n\nURL to the deb file which can be accessed using wget\n,\nName of the deb file without any spaces or special chars except hyphen.\n\n\nFor example, to install kubernetes compose, the entry should look like below.\n\n\n\n\nhttps://github.com/kubernetes/kompose/releases/download/v1.15.0/kompose-linux-amd64,kompose\n\n\n\n\n\n\nFirst part is the URL to the binary file separated by ',' name of the binary.\n\n\n\n\n\n\nNote on file names in configuration\n\n\nPlease note that file will be saved with the name mentioned in the file \n can be executed as such.\n\n\n\n\nInstall python packages (via pip)\n\n\nThis will install system wide python packages using pip. There are two lists. \npip.list\n and \npip3.list\n for python 2 and python 3 respectively. Alternatively you can specify in YAML config under \nconfig.install.python2\n or \nconfig.install.python3\n\nThis task requires \npython-pip package\n is installed, If not , will be installed anyway.\n\n\n\n\nThe list files follow similar configuration as package list files. One item per line. however you can specify version requirements as you would for requirements file.\n\n\nSimulate flag will skip installing packages, unless \nTRAVIS=true\n.\n\n\n\n\n\n\nWarning\n\n\nDon't mix Python 3 packages with Python 2 packages.\n\n\n\n\nPurge Unwanted Packages\n\n\nThis will purge Unwanted packages from the system.\n\n\n\n\nThe packages mentioned in the list purge.list or under \nconfig.purge\n in yaml will be purged\n\n\nThe format of the purge.list is similar to that of packages, one packages per line of the file and no comments or anything else.\n\n\n\n\n\n\nWarning\n\n\nIt is necessary to pass command line argument \n-d\n or \n--deboalt\n to run this task if you are using lists mode. With YML you can set the flag  \nconfig.flags.purge_enabled: true\n in config and \n-d\n is not necessary.\n\n\n\n\nReset repositories / Purge PPAs\n\n\n\n\nThis will reset the repositories added by this script, and purge ppas added by this script in the list ppa.list or config yaml.\n\n\nThis will \nNOT\n reset or remove repositories added by the DEB files.\n\n\nSimulate option has no effect on this action and ppa-purge \nWILL\n downgrade packages if necessary.\n\n\n\n\n\n\nScope of this function\n\n\nThis will \nNOT\n remove PPAs or repositories you have added manually or those added while installing DEB files.\n\n\n\n\nAll In one\n\n\nThis will perform Following actions. (In the following order)\n\n\n\n\nUpdate repository metadata\n\n\nUpgrade packages\n\n\nAdd repositories\n\n\nAdd PPAs in the list file\n\n\nInstall Apps\n\n\nInstall DEB files\n\n\nInstall Python 2 modules\n\n\nInstall Python 3 Modules\n\n\nInstall Static binaries\n\n\n\n\nThis option will honor --yes and --simulate options as individual tasks would do.\n\n\nAUTOPILOT Mode\n\n\nAUTOPILOT=true\n will execute this task.\n\n\nDelete logs\n\n\nA log file is generated containing all the output generated by the apt and other commands and contain generic information and errors .\n\n\n\n\nThis task will delete the log file \nafter-effects.log\n.\n\n\nLog file is located in the directory \nlogs\n in folder which you ran thin script.\n\n\nSometimes errors might not be written to log file but displayed on screen and vice-versa.\n\n\nPlease verify that everything went okay before deleting the logs.", 
            "title": "What can it do?"
        }, 
        {
            "location": "/tasks/#what-can-it-do", 
            "text": "", 
            "title": "What can it do?"
        }, 
        {
            "location": "/tasks/#add-repositories", 
            "text": "This can add the following repositories.   Google Earth  Google Chrome  Spotify  Visual Studio Code  Signal Desktop  Mendeley Desktop  Google cloud SDK (google-cloud-sdk   gcsfuse)  Kubernetes  Insync   Using  --fix  falg Please note that the above repositories are sometimes not updated for latest Ubuntu release and most certainly will not be available for upcoming release of Ubuntu(Alpha/Beta). It might take some time till the repositories are available for the latest release. Use -f or --fix command line option or --pre-release in case you are using a Development version of ubuntu to revert using latest available version of repositories (usually previous Ubuntu release or in case of Beta/Alpha latest stable release of ubuntu).  For more info see command line options.   Controlling which repository is added using config file You can set your YML file to decide which repository is added. Some repositories may no be supported on your architecture or distribution. Take a look at  config.yml  for example. If you omit a value, it defaults to false  ALWAYS . Do note that if you are using lists default values are different, they are mentioned in below.   Default Variables if using Lists #============================ Switches/ bools ================================ \n\n   # Latest wine builds \n   add_winehq_repo = true \n\n   #Docker community edition \n   add_docker_repo = true \n\n   #Mendeley Desktop \n   add_mendeley_repo = false \n\n   #Spotify \n   add_spotify_repo = true \n\n   #InSync \n   add_insync_repo = true \n\n   #Google Cloud SDK \n   add_googlecloud_repo = true \n\n   #Signal \n   add_signal_repo = false \n\n   #Skype \n   add_skype_repo = true \n\n   #VS code \n   add_vscode_repo = true \n\n   #Google \n   add_google_repo = true \n\n   #Kubernetes \n   add_kubernetes_repo = false \n\n   # Define Data Directory \n   data_dir = data", 
            "title": "Add Repositories"
        }, 
        {
            "location": "/tasks/#canonical-partner-repositories", 
            "text": "Canonical partner repositories are not configured or enabled for derivatives of Ubuntu because thee might be some conflicts.   Note on 32 bit   ARM Architecture   Please note that Google Chrome doesn't support 32 bit architecture, please use Chromium.  Signal, Skype, Mendeley and Visual studio code do not support 32 bit architecture.  Some repositories are not available for ARM architecture.", 
            "title": "Canonical partner repositories"
        }, 
        {
            "location": "/tasks/#add-personal-package-archives-ppa", 
            "text": "PPAs can be added using the configuration file in data directory  ./data/ppa.list  or in the YML file.  Only one ppa entry per line (No comments or anything else anywhere in the file) in the format ppa:{author}/{ppa} for example  ppa : mozillateam / firefox - next  The file will be read and the PPAs will be added from the list.  Logs will  show entry in the format  [date and time] [  PPA-Logs  ]  log    Warning   PPAs should be checked before they are added to the list. Sometimes PPAs listed in the file may not be available for all releases.  Debian does not support PPAs.", 
            "title": "Add personal package archives (PPA)"
        }, 
        {
            "location": "/tasks/#install-apt-packages", 
            "text": "Packages can be installed by using configuration lists in the data directory. This works similar to ppas   ```console                                 APT Lists   There are seven lists under key config.install.apt.[mentioned from 1-7]\n  1. administration : Contains Administrative packages\n  2. security       : contains Security related tools and packages\n  3. productivity   : Office tools, writing tools, LateX, document tools and other\n                      productivity tools, Email clients, browsers, IM clients etc.\n                    : Example : LateX, TeXStudio, Libre office, pandoc empathy, Thunderbird\n  4. multimedia     : Multimedia tools like media players, audio converters and playes etc.\n  5. development    : IDEs [Spyder, Jetbeans etc], languages [go, python, ruby, rust, java etc],\n                    : Containers [docker lxc rkt etc], Python libraries, compilers [gcc, clang]\n                    : SDKs [AWS SDK, Google Cloud SDK, open-jdk, Tensor Flow], headers and libraries[ocl-icd-dev],\n                    : Anything related to development and *-dev or *-devl packages.\n  6. other          : Everything which does not fit in the above categories.\n                    : Themes, Tools, Utilities like htop etc.\n  7. external       : Any packages which are provided by ppas, or repositories not present in\n                    : base [K/L/Ed/X]-Ubuntu distribution. There's a possibility that the repository might not\n                    : be added or may be unavailable or offline. So Keeping the list separate from\n                    : others packages minimizes errors if there are any.\n  This classification is only for ease of use and need not be strictly followed. You can put\n  'vlc' package in 'security', it will still install fine. This classification helps\n  while writing configs and editing them. Its advised to follow it if your configs\n  tend to get to couple of hundreds of lines. Also YAML file should be a valid YAML.                    Special list - Purge list   There is a special package list under key, config.purge or purge.list, which contains list of apt packages to be\n  purged from the system.\n  ```   Make sure that all the packages in the lists are available for your release. Using  -s  command line option helps. Also check for the logs for any errors or conflicts.", 
            "title": "Install apt packages"
        }, 
        {
            "location": "/tasks/#install-debian-package-archives-deb-files", 
            "text": "This will install deb files specified in the list  deb.list  or YAML config under  config.install.debian_packages .   Logs will  show entry in the format  [ date and time ] [  PKG  ]  log  for dpkg actions and  APT Logs will  show entry in the format  [ date and time ] [  APT  ]  log  for actions performed by apt commands. ( apt-get install -f  for missing packages)  Simulate  option will use  --dry-run  option in dpkg to Simulate DEB installation.  Configuration file is a  csv  file without headers. first column corresponds to URL ans the second field the file name under which the file is saved.  Each DEB file to be installed should have following entry.  URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen.  For example to install Atom Editor the entry should look like below.   https://atom-installer.github.com/v1.21.1/atom-amd64.deb,ATOM-Editor.deb   First part is the URL to the deb file separated by ',' name of the file.    Note on file names in configuration  Please note that deb file will be  saved with the name mentioned in the file. (DEB file is named  exactly  as mentioned in the second field. So if you want them to be named with extension .deb include that in the second field and avoid illegal chars)", 
            "title": "Install Debian package archives (.deb files)"
        }, 
        {
            "location": "/tasks/#install-static-binaries-to-usrlocalbin", 
            "text": "This will install binaries  bin.list  or YAML config under  config.install.binaries .   APT Logs will  show entry in the format  [ date and time ] [  APT  ]  log  for actions performed by apt commands. ( apt-get install -f  for missing packages)  Simulate  option will only download the package but not install it.  Configuration file is a  csv  file without headers. first column corresponds to URL ans the second field the file name under which the file is saved.  Each DEB file to be installed should have following entry.  URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen.  For example, to install kubernetes compose, the entry should look like below.   https://github.com/kubernetes/kompose/releases/download/v1.15.0/kompose-linux-amd64,kompose   First part is the URL to the binary file separated by ',' name of the binary.    Note on file names in configuration  Please note that file will be saved with the name mentioned in the file   can be executed as such.", 
            "title": "Install Static binaries to /usr/local/bin"
        }, 
        {
            "location": "/tasks/#install-python-packages-via-pip", 
            "text": "This will install system wide python packages using pip. There are two lists.  pip.list  and  pip3.list  for python 2 and python 3 respectively. Alternatively you can specify in YAML config under  config.install.python2  or  config.install.python3 \nThis task requires  python-pip package  is installed, If not , will be installed anyway.   The list files follow similar configuration as package list files. One item per line. however you can specify version requirements as you would for requirements file.  Simulate flag will skip installing packages, unless  TRAVIS=true .    Warning  Don't mix Python 3 packages with Python 2 packages.", 
            "title": "Install python packages (via pip)"
        }, 
        {
            "location": "/tasks/#purge-unwanted-packages", 
            "text": "This will purge Unwanted packages from the system.   The packages mentioned in the list purge.list or under  config.purge  in yaml will be purged  The format of the purge.list is similar to that of packages, one packages per line of the file and no comments or anything else.    Warning  It is necessary to pass command line argument  -d  or  --deboalt  to run this task if you are using lists mode. With YML you can set the flag   config.flags.purge_enabled: true  in config and  -d  is not necessary.", 
            "title": "Purge Unwanted Packages"
        }, 
        {
            "location": "/tasks/#reset-repositories-purge-ppas", 
            "text": "This will reset the repositories added by this script, and purge ppas added by this script in the list ppa.list or config yaml.  This will  NOT  reset or remove repositories added by the DEB files.  Simulate option has no effect on this action and ppa-purge  WILL  downgrade packages if necessary.    Scope of this function  This will  NOT  remove PPAs or repositories you have added manually or those added while installing DEB files.", 
            "title": "Reset repositories / Purge PPAs"
        }, 
        {
            "location": "/tasks/#all-in-one", 
            "text": "This will perform Following actions. (In the following order)   Update repository metadata  Upgrade packages  Add repositories  Add PPAs in the list file  Install Apps  Install DEB files  Install Python 2 modules  Install Python 3 Modules  Install Static binaries   This option will honor --yes and --simulate options as individual tasks would do.", 
            "title": "All In one"
        }, 
        {
            "location": "/tasks/#autopilot-mode", 
            "text": "AUTOPILOT=true  will execute this task.", 
            "title": "AUTOPILOT Mode"
        }, 
        {
            "location": "/tasks/#delete-logs", 
            "text": "A log file is generated containing all the output generated by the apt and other commands and contain generic information and errors .   This task will delete the log file  after-effects.log .  Log file is located in the directory  logs  in folder which you ran thin script.  Sometimes errors might not be written to log file but displayed on screen and vice-versa.  Please verify that everything went okay before deleting the logs.", 
            "title": "Delete logs"
        }, 
        {
            "location": "/configuration/", 
            "text": "Overview of Configuration files\n\n\nThis Script is designed to be flexible. You have two options of configuring this script.\n\nlist\n files directory \n/data\n \n YAML configurations are in \nconfig\n.\n\n\nConfiguration using  lists\n\n\nThese files contain list of apt packages which can be installed. Please see \nInstalling APT packages\n for more information.\n\n\n\n\n\n\n\n\nFile\n\n\nContents\n\n\n\n\n\n\n\n\n\n\nadministration\n\n\nAdministration Tools like Synaptic\n\n\n\n\n\n\ndevelopment\n\n\nUsed for development tasks eg: ruby\n\n\n\n\n\n\nexternal\n\n\nPackages from PPAs or External repositories. eg : Google Chrome, Spotify, Visual Studio Code, Google Cloud SDKs\n\n\n\n\n\n\nmultimedia\n\n\nTools to edit photos and videos, video players and editors.\n\n\n\n\n\n\nproductivity\n\n\nEmail, Chat, Office tools, Document converters etc.\n\n\n\n\n\n\nsecurity\n\n\nSecurity related tools\n\n\n\n\n\n\nutilities\n\n\nUtilities and Tools\n\n\n\n\n\n\n\n\n\n\nNon package related lists (settings, deb files, delete packages list). The use and format is explained in individual sections.\n\n\n\n\n\n\n\n\nFile\n\n\nContents\n\n\nUsed by function\n\n\nLink to section\n\n\n\n\n\n\n\n\n\n\ngsettings\n\n\nVarious gsettings\n\n\nNone Yet\n\n\nNA\n\n\n\n\n\n\npurge\n\n\nList of packages to be purged\n\n\npurge_not_required\n\n\nLink\n\n\n\n\n\n\nppa\n\n\nList of ppas to be added\n\n\nadd_ppas\n\n\nLink\n\n\n\n\n\n\ndeb\n\n\nList of DEB files to be installed (csv)\n\n\ninstall_debs\n\n\nLink\n\n\n\n\n\n\nget.mlist\n\n\nUsed by get-after-effects.sh to download required list files\n\n\nNA\n\n\nget-after-effects.sh\n\n\n\n\n\n\npip2/pip3\n\n\nPython packages (Installed System wide)\n\n\n_install_pip_packages\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nAfter you customize, might want to use simulate flag. \nsudo ./after-effects -s -L\n\n\n\n\nYAML File\n\n\nThe script can fetch remote YAML data from given url. Use \n--remote-yaml\n URL If you want to use a local config file, use \n--config-file FILENAME\n It contains following details.\n\n\n\n\nIf you specify a an option via command line and provide config file which has conflicting option, Config file takes precedence.\n\n\nRemote configuration is displayed as \n[  R-Config  ]\n in the logs and on the screen. To hide it use \n--hide-config\n\n\nCheck \nSample YAML\n configuration file \nhere.\n\n\n\n\n\n\nUsing local file\n\n\n\n\nIf you are testing, it might be a good idea to use a local file which holds this configuration data. In that  case use \n-C \nfilename\n option.\n\n\nAfter you customize, might want to use simulate flag. \nsudo ./after-effects -s -C config.yml -Y\n\n\nIf both \n-C\n and \n--remote-yaml\n are used, local config file takes priority, and remote file is \ncompletely\n ignored.\n\n\n\n\n\n\nAutomate\n\n\nSetting \nAUTOPILOT=true\n will run all the tasks specified in the YAML file, or if \n-L\n list option is used, then all tasks are executed. the order in which tasks are run is as follows.\n\n\n\n\nUpdate\n\n\nUpgrade\n\n\nAdd Repositories\n\n\nAdd PPAs [if supported]\n\n\nInstall packages\n\n\nInstall DEB packages\n\n\nInstall Python2 Modules\n\n\nInstall Python 3 Modules\n\n\nPurge unwanted Packages", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/#overview-of-configuration-files", 
            "text": "This Script is designed to be flexible. You have two options of configuring this script. list  files directory  /data    YAML configurations are in  config .", 
            "title": "Overview of Configuration files"
        }, 
        {
            "location": "/configuration/#configuration-using-lists", 
            "text": "These files contain list of apt packages which can be installed. Please see  Installing APT packages  for more information.     File  Contents      administration  Administration Tools like Synaptic    development  Used for development tasks eg: ruby    external  Packages from PPAs or External repositories. eg : Google Chrome, Spotify, Visual Studio Code, Google Cloud SDKs    multimedia  Tools to edit photos and videos, video players and editors.    productivity  Email, Chat, Office tools, Document converters etc.    security  Security related tools    utilities  Utilities and Tools      Non package related lists (settings, deb files, delete packages list). The use and format is explained in individual sections.     File  Contents  Used by function  Link to section      gsettings  Various gsettings  None Yet  NA    purge  List of packages to be purged  purge_not_required  Link    ppa  List of ppas to be added  add_ppas  Link    deb  List of DEB files to be installed (csv)  install_debs  Link    get.mlist  Used by get-after-effects.sh to download required list files  NA  get-after-effects.sh    pip2/pip3  Python packages (Installed System wide)  _install_pip_packages  Link      Tip  After you customize, might want to use simulate flag.  sudo ./after-effects -s -L", 
            "title": "Configuration using  lists"
        }, 
        {
            "location": "/configuration/#yaml-file", 
            "text": "The script can fetch remote YAML data from given url. Use  --remote-yaml  URL If you want to use a local config file, use  --config-file FILENAME  It contains following details.   If you specify a an option via command line and provide config file which has conflicting option, Config file takes precedence.  Remote configuration is displayed as  [  R-Config  ]  in the logs and on the screen. To hide it use  --hide-config  Check  Sample YAML  configuration file  here.    Using local file   If you are testing, it might be a good idea to use a local file which holds this configuration data. In that  case use  -C  filename  option.  After you customize, might want to use simulate flag.  sudo ./after-effects -s -C config.yml -Y  If both  -C  and  --remote-yaml  are used, local config file takes priority, and remote file is  completely  ignored.", 
            "title": "YAML File"
        }, 
        {
            "location": "/configuration/#automate", 
            "text": "Setting  AUTOPILOT=true  will run all the tasks specified in the YAML file, or if  -L  list option is used, then all tasks are executed. the order in which tasks are run is as follows.   Update  Upgrade  Add Repositories  Add PPAs [if supported]  Install packages  Install DEB packages  Install Python2 Modules  Install Python 3 Modules  Purge unwanted Packages", 
            "title": "Automate"
        }, 
        {
            "location": "/yaml/", 
            "text": "YAML Config\n\n\nThe configuration file is pretty much self explanatory so, I am going to just post a sample config file below. All Boolean fields are optional and if not provided or if found to be invalid, fallback to false. Default and sample configs can be found in config directory.\n\n\n# Install Config\nversion: 5\nname: Polaris\nauthor: Prasad T\n# Configurtaion\nconfig:\n  # Enabled Tasks\n  tasks:\n    update: true\n    upgrade: true\n    # Add Repos\n    # individual repos flags are mentioned under config.add_repo key\n    repo: true\n    # Add PPAs\n    ppa: true\n    # APT Packages\n    apt: true\n    # Whether to purge packages mentioned in config.purge key\n    purge: true\n    debs: true\n    pip2: true\n    pip3: true\n    binaries: true\n  # Repository Flags\n  add_repo:\n    winehq: true\n    docker: true\n    mendeley: false\n    googlecloud: true\n    spotify: true\n    vscode: true\n    skype: true\n    signal: false\n    insync: true\n    google: true\n    kubernetes: false\n  # Flags\n  flags:\n  # Simulate flag will never be overridden by remote config.\n    purge_enabled: true\n    preserve_debs: true\n    auto_yes: true\n\n  # Packages to purge\n  purge:\n    - gnome-mines\n    - gnome-sudoku\n    - aisleriot\n    - gnome-mahjongg\n  # PPA List\n  ppa:\n    - ppa:dawidd0811/neofetch\n    - ppa:yubico/stable\n    - ppa:teejee2008/ppa\n  # Install components\n  # APT Packages, Python Modules, Debian packages\n  install:\n    # Python 2 Modules\n    python2:\n      - docker-compose\n    # Python 3 Modules\n    python3:\n      - awscli\n    # Debian packages:  .deb files\n    # CSV format similar to lists\n    debian_packages:\n      - https://atom-installer.github.com/v1.28.0/atom-amd64.deb,Atom-Editor.deb\n      - https://download.teamviewer.com/download/teamviewer_i386.deb,Teamviewer.deb\n    # Static Binaries which will be placed in /usr/local/bin\n    # minikube, docker-compose, etc.\n    # Follows same pattern as Debian packages\n    # Name to be saved is second field\n    binaries:\n      - https://github.com/docker/compose/releases/download/1.20.0/docker-compose-linux-x86_64,docker-compose\n      - https://github.com/kubernetes/minikube/releases/download/v0.28.2/minikube-linux-amd64,minikube\n      - https://github.com/kubernetes/kompose/releases/download/v1.15.0/kompose-linux-amd64,kompose\n    apt:\n      # Admin related Stuff\n      administration:\n        - dconf-editor\n        - htop\n        - apt-xapian-index\n        - gdebi\n        - gparted\n        - synaptic\n        - bleachbit\n      # Security Related Stuff\n      security:\n        - gufw\n      # Productivity \n Office Tools.\n      productivity:\n        - empathy\n        - evolution\n        - realmd\n        - pandoc-data\n        - pandoc\n        - texstudio\n        - texlive-fonts-extra\n        - texlive-formats-extra\n        - texlive-fonts-recommended\n        - texlive-science\n        - texlive-generic-extra\n        - texlive-xetex\n        - texlive-luatex\n        - texlive-pstricks\n        - texlive-science\n        - texlive-extra-utils\n        - texlive-lang-english\n        - texlive-lang-other\n        - texlive-font-utils\n        - texlive-publishers\n        - gummi\n      # Multimedia Tools. Photo Editors Converting tools, plex etc.\n      multimedia:\n        - audacity\n        - vlc\n        - gimp\n        - handbrake\n        - handbrake-cli\n        - rawtherapee\n        - darktable\n        - mpv\n        - pavucontrol\n        - cheese\n      # Tools related to development.\n      development:\n        - curl\n        - spyder\n        - spyder3\n        - git\n        - shellcheck\n        - ocl-icd-dev\n        - opencl-headers\n        - clinfo\n        - vainfo\n        - vdpauinfo\n        - ocl-icd-libopencl1\n        - ruby\n        - ruby-dev\n        - python-magic\n        - putty\n        - s3cmd\n        - python3-pip\n        - python-dateutil\n        - python-pip-whl\n        - python-pip\n      # Everything Else\n      # Which is conditional\n      other:\n        - gnome-online-miners\n      # Packages supplied by external repositories \n PPAs\n      # Dont Mix packages provided by distribution and PPAs\n      # Sometimes external repos and ppas fail, so better isolate it.\n      external:\n        - google-chrome-stable\n        - spotify-client\n        - code\n        - google-cloud-sdk\n        - gcsfuse\n        - docker-ce", 
            "title": "Example Config YAML"
        }, 
        {
            "location": "/yaml/#yaml-config", 
            "text": "The configuration file is pretty much self explanatory so, I am going to just post a sample config file below. All Boolean fields are optional and if not provided or if found to be invalid, fallback to false. Default and sample configs can be found in config directory.  # Install Config\nversion: 5\nname: Polaris\nauthor: Prasad T\n# Configurtaion\nconfig:\n  # Enabled Tasks\n  tasks:\n    update: true\n    upgrade: true\n    # Add Repos\n    # individual repos flags are mentioned under config.add_repo key\n    repo: true\n    # Add PPAs\n    ppa: true\n    # APT Packages\n    apt: true\n    # Whether to purge packages mentioned in config.purge key\n    purge: true\n    debs: true\n    pip2: true\n    pip3: true\n    binaries: true\n  # Repository Flags\n  add_repo:\n    winehq: true\n    docker: true\n    mendeley: false\n    googlecloud: true\n    spotify: true\n    vscode: true\n    skype: true\n    signal: false\n    insync: true\n    google: true\n    kubernetes: false\n  # Flags\n  flags:\n  # Simulate flag will never be overridden by remote config.\n    purge_enabled: true\n    preserve_debs: true\n    auto_yes: true\n\n  # Packages to purge\n  purge:\n    - gnome-mines\n    - gnome-sudoku\n    - aisleriot\n    - gnome-mahjongg\n  # PPA List\n  ppa:\n    - ppa:dawidd0811/neofetch\n    - ppa:yubico/stable\n    - ppa:teejee2008/ppa\n  # Install components\n  # APT Packages, Python Modules, Debian packages\n  install:\n    # Python 2 Modules\n    python2:\n      - docker-compose\n    # Python 3 Modules\n    python3:\n      - awscli\n    # Debian packages:  .deb files\n    # CSV format similar to lists\n    debian_packages:\n      - https://atom-installer.github.com/v1.28.0/atom-amd64.deb,Atom-Editor.deb\n      - https://download.teamviewer.com/download/teamviewer_i386.deb,Teamviewer.deb\n    # Static Binaries which will be placed in /usr/local/bin\n    # minikube, docker-compose, etc.\n    # Follows same pattern as Debian packages\n    # Name to be saved is second field\n    binaries:\n      - https://github.com/docker/compose/releases/download/1.20.0/docker-compose-linux-x86_64,docker-compose\n      - https://github.com/kubernetes/minikube/releases/download/v0.28.2/minikube-linux-amd64,minikube\n      - https://github.com/kubernetes/kompose/releases/download/v1.15.0/kompose-linux-amd64,kompose\n    apt:\n      # Admin related Stuff\n      administration:\n        - dconf-editor\n        - htop\n        - apt-xapian-index\n        - gdebi\n        - gparted\n        - synaptic\n        - bleachbit\n      # Security Related Stuff\n      security:\n        - gufw\n      # Productivity   Office Tools.\n      productivity:\n        - empathy\n        - evolution\n        - realmd\n        - pandoc-data\n        - pandoc\n        - texstudio\n        - texlive-fonts-extra\n        - texlive-formats-extra\n        - texlive-fonts-recommended\n        - texlive-science\n        - texlive-generic-extra\n        - texlive-xetex\n        - texlive-luatex\n        - texlive-pstricks\n        - texlive-science\n        - texlive-extra-utils\n        - texlive-lang-english\n        - texlive-lang-other\n        - texlive-font-utils\n        - texlive-publishers\n        - gummi\n      # Multimedia Tools. Photo Editors Converting tools, plex etc.\n      multimedia:\n        - audacity\n        - vlc\n        - gimp\n        - handbrake\n        - handbrake-cli\n        - rawtherapee\n        - darktable\n        - mpv\n        - pavucontrol\n        - cheese\n      # Tools related to development.\n      development:\n        - curl\n        - spyder\n        - spyder3\n        - git\n        - shellcheck\n        - ocl-icd-dev\n        - opencl-headers\n        - clinfo\n        - vainfo\n        - vdpauinfo\n        - ocl-icd-libopencl1\n        - ruby\n        - ruby-dev\n        - python-magic\n        - putty\n        - s3cmd\n        - python3-pip\n        - python-dateutil\n        - python-pip-whl\n        - python-pip\n      # Everything Else\n      # Which is conditional\n      other:\n        - gnome-online-miners\n      # Packages supplied by external repositories   PPAs\n      # Dont Mix packages provided by distribution and PPAs\n      # Sometimes external repos and ppas fail, so better isolate it.\n      external:\n        - google-chrome-stable\n        - spotify-client\n        - code\n        - google-cloud-sdk\n        - gcsfuse\n        - docker-ce", 
            "title": "YAML Config"
        }, 
        {
            "location": "/logs/", 
            "text": "Logs\n\n\n\n\nLogs are written to a file \ncurrent-dir\n/logs/after-effects.log\n.\n\n\nTime-stamps in the logs may not be accurate because some commands buffer outputs.\n\n\n\n\n\n\nSensitive\n\n\nLog files might contain sensitive information or personally identifying information.\nThey are not uploaded anywhere.", 
            "title": "Logs"
        }, 
        {
            "location": "/logs/#logs", 
            "text": "Logs are written to a file  current-dir /logs/after-effects.log .  Time-stamps in the logs may not be accurate because some commands buffer outputs.    Sensitive  Log files might contain sensitive information or personally identifying information.\nThey are not uploaded anywhere.", 
            "title": "Logs"
        }, 
        {
            "location": "/testing/", 
            "text": "CI and Testing\n\n\n\n\nTest Scripts\n\n\nTest Scripts assume that you are running on Travis. So They might fail if some environment variables are not set. Please see, \nTravis environment variables\n.\n\n\n\n\nFollowing Tests are done on Travis-CI.\n\n\n\n\nshellcheck\n every executable bash script (Job #build.1)\n\n\nTest on Ubuntu Bionic Beaver (Job #build.2)\n\n\nTest on Ubuntu Xenial (Job #build.3)\n\n\nTest on Ubuntu Trusty (Host) (Job #build.4)\n\n\nTest on Debian 9 Stretch (Job #build.5)\n\n\nTest on Debian 8 Jessie (Job #build.6)\n\n\nTest on Ubuntu Cosmic  (Job #build.7)\n\n\nTest on Debian 10 Buster (Job #build.8)\n\n\nBuild, Test \n deploy documentation (Job #build.9).\n\n\n\n\n\n\nInfo\n\n\n\n\nTrusty tests do not install indicator-kdeconnect, peek, openjdk-8-jdk, gnome-todo , gnome-calendar, polari and their PPAs. Please modify your lists accordingly.\n\n\nBuild scripts depend on Netlify builds to succeed access latest YAML files. So, if a Netlify build fails, either Travis jobs might fail or might not be tested with latest YAMLs. Currently there is not way to properly and easily communicate with two as Netlify APIs do not provide easy way to access build status per branch or commit.\n\n\n\n\n\n\n\n\nTests on Cosmic Cuttlefish use base image from \nhttp://cdimage.ubuntu.com/ubuntu-base/daily/\n\n\nDockerfiles used for building the image are in \n/dockerfiles\n directory, they use official Ubuntu base images with script dependencies.\n\n\nTest scripts are located in \n/tests\n directory.\n\n\nSince its a time consuming process only simulated install is done on CI. Linux mint and Elementary are not tested in containers, but \nmay\n be in the future.\n\n\nIt is possible that there might be some errors specific to your setup. Please report if so. It is \nStrongly\n advised to try install apps and deb files in simulate mode first before proceeding with actual installation.\n\n\n\n\n\n\nWarning\n\n\nNever\n set environment variable \nCI=true\n or \nTRAVIS=true\n, unless you are running in a CI environment or are sure of its effects.", 
            "title": "Testing"
        }, 
        {
            "location": "/testing/#ci-and-testing", 
            "text": "Test Scripts  Test Scripts assume that you are running on Travis. So They might fail if some environment variables are not set. Please see,  Travis environment variables .   Following Tests are done on Travis-CI.   shellcheck  every executable bash script (Job #build.1)  Test on Ubuntu Bionic Beaver (Job #build.2)  Test on Ubuntu Xenial (Job #build.3)  Test on Ubuntu Trusty (Host) (Job #build.4)  Test on Debian 9 Stretch (Job #build.5)  Test on Debian 8 Jessie (Job #build.6)  Test on Ubuntu Cosmic  (Job #build.7)  Test on Debian 10 Buster (Job #build.8)  Build, Test   deploy documentation (Job #build.9).    Info   Trusty tests do not install indicator-kdeconnect, peek, openjdk-8-jdk, gnome-todo , gnome-calendar, polari and their PPAs. Please modify your lists accordingly.  Build scripts depend on Netlify builds to succeed access latest YAML files. So, if a Netlify build fails, either Travis jobs might fail or might not be tested with latest YAMLs. Currently there is not way to properly and easily communicate with two as Netlify APIs do not provide easy way to access build status per branch or commit.     Tests on Cosmic Cuttlefish use base image from  http://cdimage.ubuntu.com/ubuntu-base/daily/  Dockerfiles used for building the image are in  /dockerfiles  directory, they use official Ubuntu base images with script dependencies.  Test scripts are located in  /tests  directory.  Since its a time consuming process only simulated install is done on CI. Linux mint and Elementary are not tested in containers, but  may  be in the future.  It is possible that there might be some errors specific to your setup. Please report if so. It is  Strongly  advised to try install apps and deb files in simulate mode first before proceeding with actual installation.    Warning  Never  set environment variable  CI=true  or  TRAVIS=true , unless you are running in a CI environment or are sure of its effects.", 
            "title": "CI and Testing"
        }, 
        {
            "location": "/changelogs/", 
            "text": "Change logs\n\n\nVersion 5.3.1\n\n\n\n\nAdd preliminary support for Debian 10 Buster.\n\n\nFixed typos in documentation.\n\n\nRemoved old files, Display git tag message in releases.\n\n\n\n\nVersion 5.3.0\n\n\n\n\nMove config files from /api to /config\n\n\nUpdate spotify Keys [Fixes Spotify repos]\n\n\nFix a bug which prevented Insync repo being added\n\n\n\n\nVersion 5.2.0\n\n\n\n\nNew Feature: Static binaries installation (kompose,docker-compose etc)\n\n\nAll script tmp files are now created /tmp/ae/\n\n\n\n\nVersion 5.1.2\n\n\n\n\nFix get script URLS.\n\n\nFix kubernetes repo url \n repos for mint\n\n\n\n\nVersion 5.1.0\n\n\n\n\nSpecify YAML config via URL. You can use config YAMLs saved as gists.\n\n\n\n\nVersion 5.0\n\n\n\n\nRemove Pre and Post Hooks.\n\n\nConfiguration can be now done using YAML file. Its easer \n gives more flexibility\n\n\nLot of improvements \n bug fixes.\n\n\nNow tagged versions are released to Github releases.\n\n\nConsolidate test scripts.\n\n\nDrop Artful support.\n\n\nAdd support for Elementary OS 5 - Juno \n Mint 19 Tara.\n\n\nVersion checks also use YAML files.\n\n\nARM support for some repositories. (not all repos support ARM)\n\n\nMove .redirects data to netlify toml\n\n\nGroundwork to move to parser written in Go.\n\n\nYAML provides more configuration options. Individual repos \n tasks can now be controlled via YAML file.\n\n\n\n\nVersion 4.0\n\n\n\n\nPre and Post Hooks for scripts.\n\n\nCustom list of scripts can be run Before and after all the tasks.\n\n\nAdd version checks, always run latest version\n\n\nBrand new documentation site\n\n\nUse \nmkdocs\n to generate documentation\n\n\nAutomatically push \n deploy to gh-pages\n\n\nUse Netlify to manage gh-pages site\n\n\nCheck if script is in current directory, to avoid errors on hooks\n\n\nImprove log file format: Reduce clutter\n\n\nBug fixes and typo fixes\n\n\nSimplify TS logging\n\n\nRemote configuration for stats and stats server\n\n\nAbility to blacklist a release\n\n\nPrepare \n add skeleton for stats reporting\n\n\n\n\nVersion 3.6\n\n\n\n\nAdd Option to install system wide python packages using pip\n\n\nPromote Bionic to stable and update code-names\n\n\nUpdate pre-release to cosmic, rename test script for pre release\n\n\nRemove unused dockerfiles\n\n\n\n\nVersion 3.4\n\n\n\n\nDelete cached and downloaded DEBs. (Can be changed with \n-k\n flag )\n\n\nRemove Gnome Specific stuff from default list\n\n\nRemove PPAs incompatible with bionic\n\n\nBionic is supported with --pre-release flag only with default list.\n\n\n\n\nVersion 3.3\n\n\n\n\nAdd Signal Desktop repository\n\n\nBetter way to handle EOL error messages\n\n\nFix: Visual Studio Code GPG key not deleted while removing repos.\n\n\nLint Readme Markdown\n\n\nNuke Sub-modules\n\n\n\n\nVersion 3.2\n\n\n\n\nAllow Bionic test to fail on Travis.\n\n\nOnly print logs in Travis if there is an error or a flag is passed.\n\n\nSwitch to sub-modules for data directory\n\n\nList files have their own repo now.\n\n\nZesty reaches EOL soon. Remove it.\n\n\nUse daily images for bionic\n\n\n\n\nVersion 3.1\n\n\n\n\nAdded Support for Upcoming Ubuntu release bionic.\n\n\nAdded an option to use repository for last stable release on bionic.\n\n\nUse Ubuntu Base 18.04 LTS (Bionic Beaver) daily build to build docker image.\n\n\nAllow Bionic tests to fail on Travis CI.\n\n\nDockerfiles \n tests for bionic.\n\n\nInform in script if running on Upcoming release.\n\n\nDrop google-cloud-sdk from fix_repo_not_available. Use \n--pre-release\n if using beta/alpha Ubuntu release.\n\n\nAdd Visual studio to repos instead of deb files\n\n\nRename logging directory to after-effects\n\n\n\n\nVersion 3.0\n\n\n\n\n\n\nAdd Confirmation dialog using whiptail for Actions like Adding PPA, Repositories, Installing Apps, and Deb files\n\n\n\n\n\n\nProvide an option via command line to bypass the confirmation dialog for ci and automated environments or when its too annoying\n\n\n\n\nIf the simulate option is selected then Only calculate the upgrade but do not perform upgrade.\n\n\nAdded improved Simulate options. Helpful when just want to change somethings and test scripts without really downloading and installing packages\n\n\nSimulate option is by default false and can be toggled by passing \n-s\n or \n--simulate\n while running the script via command line\n\n\nDo not Enable Canonical Partner repositories in Ubuntu derivatives as they are enabled in installer or are different than Ubuntu. This leaves Partner repositories as they were before\n\n\nAdd Feature: Purge Unwanted Packages\n\n\nImproved logging . Redirecting errors and adding time-stamps works better.\n\n\nTravis CI and Docker Testing\n\n\n\n\nVersion 2.0\n\n\n\n\nComplete rewrite from scratch\n\n\nImprovements in logging and console output\n\n\nReduced verbosity in terminal output\n\n\nFlexible with packages and deb files\n\n\nReduced complex dependencies\n\n\nEasy to configure\n\n\nAdd Simulate install option for installing deb files and apps. Easier to test scripts now .\n\n\n\n\nVersion 1.0\n\n\n\n\nInitial upload.", 
            "title": "Changelogs"
        }, 
        {
            "location": "/changelogs/#change-logs", 
            "text": "", 
            "title": "Change logs"
        }, 
        {
            "location": "/changelogs/#version-531", 
            "text": "Add preliminary support for Debian 10 Buster.  Fixed typos in documentation.  Removed old files, Display git tag message in releases.", 
            "title": "Version 5.3.1"
        }, 
        {
            "location": "/changelogs/#version-530", 
            "text": "Move config files from /api to /config  Update spotify Keys [Fixes Spotify repos]  Fix a bug which prevented Insync repo being added", 
            "title": "Version 5.3.0"
        }, 
        {
            "location": "/changelogs/#version-520", 
            "text": "New Feature: Static binaries installation (kompose,docker-compose etc)  All script tmp files are now created /tmp/ae/", 
            "title": "Version 5.2.0"
        }, 
        {
            "location": "/changelogs/#version-512", 
            "text": "Fix get script URLS.  Fix kubernetes repo url   repos for mint", 
            "title": "Version 5.1.2"
        }, 
        {
            "location": "/changelogs/#version-510", 
            "text": "Specify YAML config via URL. You can use config YAMLs saved as gists.", 
            "title": "Version 5.1.0"
        }, 
        {
            "location": "/changelogs/#version-50", 
            "text": "Remove Pre and Post Hooks.  Configuration can be now done using YAML file. Its easer   gives more flexibility  Lot of improvements   bug fixes.  Now tagged versions are released to Github releases.  Consolidate test scripts.  Drop Artful support.  Add support for Elementary OS 5 - Juno   Mint 19 Tara.  Version checks also use YAML files.  ARM support for some repositories. (not all repos support ARM)  Move .redirects data to netlify toml  Groundwork to move to parser written in Go.  YAML provides more configuration options. Individual repos   tasks can now be controlled via YAML file.", 
            "title": "Version 5.0"
        }, 
        {
            "location": "/changelogs/#version-40", 
            "text": "Pre and Post Hooks for scripts.  Custom list of scripts can be run Before and after all the tasks.  Add version checks, always run latest version  Brand new documentation site  Use  mkdocs  to generate documentation  Automatically push   deploy to gh-pages  Use Netlify to manage gh-pages site  Check if script is in current directory, to avoid errors on hooks  Improve log file format: Reduce clutter  Bug fixes and typo fixes  Simplify TS logging  Remote configuration for stats and stats server  Ability to blacklist a release  Prepare   add skeleton for stats reporting", 
            "title": "Version 4.0"
        }, 
        {
            "location": "/changelogs/#version-36", 
            "text": "Add Option to install system wide python packages using pip  Promote Bionic to stable and update code-names  Update pre-release to cosmic, rename test script for pre release  Remove unused dockerfiles", 
            "title": "Version 3.6"
        }, 
        {
            "location": "/changelogs/#version-34", 
            "text": "Delete cached and downloaded DEBs. (Can be changed with  -k  flag )  Remove Gnome Specific stuff from default list  Remove PPAs incompatible with bionic  Bionic is supported with --pre-release flag only with default list.", 
            "title": "Version 3.4"
        }, 
        {
            "location": "/changelogs/#version-33", 
            "text": "Add Signal Desktop repository  Better way to handle EOL error messages  Fix: Visual Studio Code GPG key not deleted while removing repos.  Lint Readme Markdown  Nuke Sub-modules", 
            "title": "Version 3.3"
        }, 
        {
            "location": "/changelogs/#version-32", 
            "text": "Allow Bionic test to fail on Travis.  Only print logs in Travis if there is an error or a flag is passed.  Switch to sub-modules for data directory  List files have their own repo now.  Zesty reaches EOL soon. Remove it.  Use daily images for bionic", 
            "title": "Version 3.2"
        }, 
        {
            "location": "/changelogs/#version-31", 
            "text": "Added Support for Upcoming Ubuntu release bionic.  Added an option to use repository for last stable release on bionic.  Use Ubuntu Base 18.04 LTS (Bionic Beaver) daily build to build docker image.  Allow Bionic tests to fail on Travis CI.  Dockerfiles   tests for bionic.  Inform in script if running on Upcoming release.  Drop google-cloud-sdk from fix_repo_not_available. Use  --pre-release  if using beta/alpha Ubuntu release.  Add Visual studio to repos instead of deb files  Rename logging directory to after-effects", 
            "title": "Version 3.1"
        }, 
        {
            "location": "/changelogs/#version-30", 
            "text": "Add Confirmation dialog using whiptail for Actions like Adding PPA, Repositories, Installing Apps, and Deb files    Provide an option via command line to bypass the confirmation dialog for ci and automated environments or when its too annoying   If the simulate option is selected then Only calculate the upgrade but do not perform upgrade.  Added improved Simulate options. Helpful when just want to change somethings and test scripts without really downloading and installing packages  Simulate option is by default false and can be toggled by passing  -s  or  --simulate  while running the script via command line  Do not Enable Canonical Partner repositories in Ubuntu derivatives as they are enabled in installer or are different than Ubuntu. This leaves Partner repositories as they were before  Add Feature: Purge Unwanted Packages  Improved logging . Redirecting errors and adding time-stamps works better.  Travis CI and Docker Testing", 
            "title": "Version 3.0"
        }, 
        {
            "location": "/changelogs/#version-20", 
            "text": "Complete rewrite from scratch  Improvements in logging and console output  Reduced verbosity in terminal output  Flexible with packages and deb files  Reduced complex dependencies  Easy to configure  Add Simulate install option for installing deb files and apps. Easier to test scripts now .", 
            "title": "Version 2.0"
        }, 
        {
            "location": "/changelogs/#version-10", 
            "text": "Initial upload.", 
            "title": "Version 1.0"
        }, 
        {
            "location": "/license/", 
            "text": "License\n\n\nThis project is licensed under GPL v3. You should have received a copy of the\nlicense along with this software.\n\n\nExternal libraries and tools\n\n\nThis project uses \nmkdocs\n for documentation and\n\nmkdocs-material\n theme.", 
            "title": "License"
        }, 
        {
            "location": "/license/#license", 
            "text": "This project is licensed under GPL v3. You should have received a copy of the\nlicense along with this software.", 
            "title": "License"
        }, 
        {
            "location": "/license/#external-libraries-and-tools", 
            "text": "This project uses  mkdocs  for documentation and mkdocs-material  theme.", 
            "title": "External libraries and tools"
        }, 
        {
            "location": "/privacy/", 
            "text": "Privacy Policy\n\n\nPrivacy policy related to website is available \nhere\n.\n\n\nAnonymous stats collection\n\n\n\n\nInfo\n\n\nYour passwords, usernames, environment variables or anything sensitive is not collected.\n\n\n\n\nThe script \nafter-effects\n collects anonymous usage statistics. The following might be collected.\n\n\n\n\nRandomized UUID generated per run.\n\n\nLast exit code.\n\n\nSystem Architecture (x64/x86/ARM/ARM64).\n\n\nAmount of RAM \n CPU Model\n\n\nNumber of GPU \n GPU Vendor\n\n\nTotal execution time.\n\n\nDistribution name (Ubuntu, Linux Mint etc.)\n\n\nDistribution code name (bionic, artful etc)\n\n\nFeature/Task selected.\n\n\nFlags used.\n\n\nTimezone and system language.\n\n\nHost-name.\n\n\n\n\n\n\nTip\n\n\n\n\nNo personally identifiable information is collected or reported back.\n\n\nThis feature can be disabled via \n--no-stats\n flag.", 
            "title": "Privacy Policy"
        }, 
        {
            "location": "/privacy/#privacy-policy", 
            "text": "Privacy policy related to website is available  here .", 
            "title": "Privacy Policy"
        }, 
        {
            "location": "/privacy/#anonymous-stats-collection", 
            "text": "Info  Your passwords, usernames, environment variables or anything sensitive is not collected.   The script  after-effects  collects anonymous usage statistics. The following might be collected.   Randomized UUID generated per run.  Last exit code.  System Architecture (x64/x86/ARM/ARM64).  Amount of RAM   CPU Model  Number of GPU   GPU Vendor  Total execution time.  Distribution name (Ubuntu, Linux Mint etc.)  Distribution code name (bionic, artful etc)  Feature/Task selected.  Flags used.  Timezone and system language.  Host-name.    Tip   No personally identifiable information is collected or reported back.  This feature can be disabled via  --no-stats  flag.", 
            "title": "Anonymous stats collection"
        }
    ]
}